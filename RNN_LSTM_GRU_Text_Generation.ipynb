{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcUibv3CE55M"
      },
      "source": [
        "# Reading the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ncm6GS9uO16u",
        "outputId": "b8265aa9-40f5-4a93-a8f1-d8ee26cfc488"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.15)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.3.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.6.0+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.6.0+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 multiprocess-0.70.16 xxhash-3.5.0\n"
          ]
        }
      ],
      "source": [
        "pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 957,
          "referenced_widgets": [
            "48a8374f0835482cafaae4ee6838f79c",
            "cc020ebb3672434ea09a98c9ddb82615",
            "267f01ace3b2424ba27e83f13e85c1e3",
            "e40a4e4a6bbb45e1805ecd736b629ec8",
            "419dce4950e543d8b15855c67fa662cc",
            "615c8bdc61ca4001af0f0216c9134a30",
            "e4485c11ae9a45d097fb6ab6614cd64f",
            "099d48c315f940ba887142d0b9150c86",
            "c580d7a634a54b4fae6f07eedf9bd3b2",
            "c1c7cea2bd594f3fac9bb50c1bedebfc",
            "7a6e4d6aaef7414097c83eeb7f2eb94c",
            "a339a69c714b425494ea7fa9ed8ac86d",
            "8b71050225d64465bc9e3a1f3e6b4fa0",
            "72947b90ee174f6ca3b921da9b2f2ed4",
            "ee88035ac2944594b4c392eae66b948a",
            "307973e6c0cf48e4b33d123fc69be668",
            "71556afa13d149c080359e60da14ccd5",
            "ab44205b591040008cfcd38b514bdf9e",
            "159704455da24d5c921dad671b711f83",
            "a19ac071607a4c729b6a43e50f9c501f",
            "6dc1d362becf4887a4edefdb355d88eb",
            "07e2a08023cd4402a6f97c04ad108d56",
            "9c0be4f8a2ab4516ac793727f5366a6e",
            "20127fac11fc45b6a4aecadedbfbd5ee",
            "7bc1df8c8b554905bc58b4be353fc3b8",
            "deebdf3841c1450e831a6245d010bb89",
            "bcc076863d9649ebb1261c267c00ebcf",
            "b0b74c63af3a41968ba1e40c0791b3fc",
            "9f4077d7ea9348d4b1b0feeeb96b3e07",
            "463358cf7af54c83a13a640db5f073b6",
            "37a4d5482d67470d9c39b7b07019fcc7",
            "bb7a144c438b4e7c80821273bf71b0eb",
            "2bc0011c15c34fcdb89cecfaf702787b",
            "b01bed25877a49d2a60fb6c23b461506",
            "eefe5ce1cf534f2daa31d9cd04f21dd0",
            "f973b13ba5d4499d851aeee200399e52",
            "2914bb5a931f474690ce3138c6674cd2",
            "b6cc5724c72a4749aef923ea610834f0",
            "cf67dc7ff2bb40509c67d4eac0b3b34a",
            "5a4b9b3a951a45a7a5c35f498d64bc6a",
            "f74e9f85a49942a6b3a48e1748570153",
            "34dd472d33c244059cdd3396c45fffac",
            "f72aa16946ab446ebe2358c864426999",
            "69732fa3642643249be53cf913b54679",
            "e6544e6e9c5644fa983e887569e114e3",
            "c29fa66a298d4f09a8bd48a1598d8aab",
            "1b999b8b0ae242d1a553f54140c19238",
            "99d2a351135e42929a0515e0bd483c46",
            "ea0c77ac9c68472faf576963bcaf9a64",
            "d02542b747034c5390d3c30eb9080d5d",
            "c90da13efaea458191ee0db0c5b84da8",
            "2758ffd089864c898db9d1f7a0e8d0fa",
            "bda00152caac45c591c85ecb2a0e3264",
            "4636cff815414408bb3a0903c38e0de5",
            "c0b761c543894f83933693d0fe8affda",
            "f358b3cd52cb4db486b3dbe97c6346c4",
            "4bfffad11d8847f3a915b6d4f92057b3",
            "f192cf1981c94506806eb9a19093b0c0",
            "33a6c33274c5461d80f9f77579c8b3f4",
            "10850bb4c5a84e469f9601bfc1e7dcb8",
            "e5215a54b3074ad7b13f956a07567730",
            "151de66e80f340f9bf601b1e3e25a421",
            "86a5a2f4678149e38f7a8961be08f00b",
            "7f8cebe472494317aff3d88375d476df",
            "de4eea5277e34cefa537e014923fae5e",
            "bc6e5bc1c3d149169debc876db942541"
          ]
        },
        "id": "-W59hoyNOtC4",
        "outputId": "186dcb24-56f0-4649-a373-98bd5f273b2f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48a8374f0835482cafaae4ee6838f79c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/6.10k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a339a69c714b425494ea7fa9ed8ac86d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tiny_shakespeare.py:   0%|          | 0.00/3.73k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c0be4f8a2ab4516ac793727f5366a6e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.12M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b01bed25877a49d2a60fb6c23b461506",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e6544e6e9c5644fa983e887569e114e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation split:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f358b3cd52cb4db486b3dbe97c6346c4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n",
            "All:\n",
            "We know't, we know't.\n",
            "\n",
            "First Citizen:\n",
            "Let us kill him, and we'll have corn at our own price.\n",
            "Is't a verdict?\n",
            "\n",
            "All:\n",
            "No more talking on't; let it be done: away, away!\n",
            "\n",
            "Second Citizen:\n",
            "One word, good citizens.\n",
            "\n",
            "First Citizen:\n",
            "We are accounted poor citizens, the patricians good.\n",
            "What authority surfeits on would relieve us: if they\n",
            "would yield us but the superfluity, while it were\n",
            "wholesome, we might guess they relieved us humanely;\n",
            "but they think we are too dear: the leanness that\n",
            "afflicts us, the object of our misery, is as an\n",
            "inventory to particularise their abundance; our\n",
            "sufferance is a gain to them Let us revenge this with\n",
            "our pikes, ere we become rakes: for the gods know I\n",
            "speak this in hunger for bread, not in thirst for revenge.\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Load the dataset\n",
        "dataset = load_dataset(\"karpathy/tiny_shakespeare\" ,trust_remote_code=True,split = 'train')\n",
        "\n",
        "# View first few lines\n",
        "print(dataset[0]['text'][:1000])  # print first 1000 characters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfVnlw7XQS8w",
        "outputId": "9ec2a647-980f-4761-c9d2-a71bb874e9c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1, 1)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdzEJ_r6QOA8"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3U2qQXStORgt"
      },
      "source": [
        "### Word tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpomy7wrK5VO",
        "outputId": "560feeb2-5e41-4e26-cd96-f846565a1e33"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (258333 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['first', 'citizen', ':', 'before', 'we', 'proceed', 'any', 'further', ',', 'hear', 'me', 'speak', '.', 'all', ':', 'speak', ',', 'speak', '.', 'first', 'citizen', ':', 'you', 'are', 'all', 'resolved', 'rather', 'to', 'die', 'than', 'to', 'fa', '##mis', '##h', '?', 'all', ':', 'resolved', '.', 'resolved', '.', 'first', 'citizen', ':', 'first', ',', 'you', 'know', 'cai', '##us', 'marc', '##ius', 'is', 'chief', 'enemy', 'to', 'the', 'people', '.', 'all', ':', 'we', 'know', \"'\", 't', ',', 'we', 'know', \"'\", 't', '.', 'first', 'citizen', ':', 'let', 'us', 'kill', 'him', ',', 'and', 'we', \"'\", 'll', 'have', 'corn', 'at', 'our', 'own', 'price', '.', 'is', \"'\", 't', 'a', 'verdict', '?', 'all', ':', 'no', 'more']\n"
          ]
        }
      ],
      "source": [
        " #WordPiece tokenization\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "text = dataset[0]['text']\n",
        "tokens_WP = tokenizer.tokenize(text)\n",
        "print(tokens_WP[:100])  # ['un', '##believable']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215,
          "referenced_widgets": [
            "969d7128c95b4d96b9a88b19047941f6",
            "d6e6289210974699879732edd0aa4714",
            "0ba80e0e0e6944758ece0e6dcb0338f3",
            "007c89c59d8e48a48d19898f7698aedc",
            "5b12b6e68dd243f6ae52b00912ddb543",
            "8f6e5436a3a14f25be8f342b9d8fef84",
            "787f2f9a94624d51a31f83d3797eb30c",
            "1f19167c203c4d85b40db2ee92f32c5c",
            "82f6fe8978fd4a198bc74e9085e10005",
            "2daae658f29548b3aa7874905fa2085a",
            "433728dba5a5452fb8b1fe3a966e8f28",
            "3da9c708cce349c49232a817edf9e4e4",
            "ab8d4c408dfb4c37a1735845284fe5c0",
            "045ee62631f24abd903d94a7dc7de6ac",
            "15212aad999f44a9ad0daab5fb585a17",
            "9dfce5263b544e4db5d943b3f0d3b23a",
            "7d03504d64594fc08149d45f87273fae",
            "76c48825ee804b0daa33b146b6f29352",
            "39cba0a6253c441c809dcc96226e24b8",
            "87712890938c4e9abea53114a1b62084",
            "34415fc12ddd40ec942d8af2bab3c054",
            "4c2d16d50d094b55aa3bdd3db1d0f417",
            "003fc00db5a14e888e3d0436430caa1a",
            "5efe2a70ac824d8ea35dcc62cdc8dd82",
            "731129cc7755460db8cff585812fbd16",
            "6f80569c99334c79b6956f1dc7a6a004",
            "efaafc2a0969435eb74f55f260e1606a",
            "89c31d946e344638a8b0099cdde67335",
            "116888c72e474c798ad60c3955ca3711",
            "5b655f2e4340407fa6ad78346f9c8639",
            "ef405ef7ba73409b945b3479b2b42bc1",
            "beb358cafb5848238bc9e3e759134670",
            "dc6d907bf21746eead05056201d9e17a",
            "8ad51c89023e45fba680edee580d40ae",
            "f8190896aee846119d15052e6483acfe",
            "021fb054a4c34413ae675d923323cf81",
            "0d6d28dbfbb145dba0d0419ba8bfe741",
            "fe43beb413ad4d3abbe10def00a20f3a",
            "24a55b3942a744ecb79a758cf1c11cb5",
            "f9484ff29a044589ab8ee217ae9b27c3",
            "baeda91319074e27bf4f507d4a64b9ef",
            "cf8ada31bd3646adb993063a6045db6f",
            "95fc890fc1d14f12ab20fab62965845a",
            "14bd2737052f49fb9a12b5e26e058dcb",
            "24935f46519b47f58e0f864228ca615f",
            "a31a96b22da3435b814190a61ff161dc",
            "4a4c97b4bf784afbb082e9dad2d0183d",
            "f5545db5a29447f1aa2475df5fc58618",
            "4480e4c8e73248aabe7ed59471e0e69c",
            "9988673546324902a76369dfda65aa47",
            "4612cf302057460c8b4837ca83102dcb",
            "f63a36c9d89848048de64916654054bf",
            "0366b145a95449328c6f657a7a2902aa",
            "d7c13642d1d64f46956a963304ae242f",
            "3d4871114571462f89d3e3a39d018c28"
          ]
        },
        "id": "eXTl_E9sXBum",
        "outputId": "b99b1fd8-2a7a-4e53-ccfd-7e5934f92f5a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "969d7128c95b4d96b9a88b19047941f6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3da9c708cce349c49232a817edf9e4e4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "003fc00db5a14e888e3d0436430caa1a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ad51c89023e45fba680edee580d40ae",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "24935f46519b47f58e0f864228ca615f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['First', 'ĠCitizen', ':', 'Ċ', 'Before', 'Ġwe', 'Ġproceed', 'Ġany', 'Ġfurther', ',', 'Ġhear', 'Ġme', 'Ġspeak', '.', 'Ċ', 'Ċ', 'All', ':', 'Ċ', 'Spe', 'ak', ',', 'Ġspeak', '.', 'Ċ', 'Ċ', 'First', 'ĠCitizen', ':', 'Ċ', 'You']\n"
          ]
        }
      ],
      "source": [
        "#GPT-like model, BPE-style behavior\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "\n",
        "text = dataset[0]['text']\n",
        "tokens_BPE = tokenizer.tokenize(text[:100])\n",
        "print(tokens_BPE[:100])  # ['un', 'believable'] or ['unbel', 'ievable'] (depending on merges)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdJqcIZy6MIN"
      },
      "source": [
        "BPE make spaces into special characters.We will continue with WordPiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "OOKfUBkb6pjQ",
        "outputId": "fb9a4d77-173c-4511-f774-91d01730966f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_tokens"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-46a863c9-47fd-46a5-8cb0-fd9b0d9c413d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Stem</th>\n",
              "      <th>Lemma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>first</td>\n",
              "      <td>first</td>\n",
              "      <td>first</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>citizen</td>\n",
              "      <td>citizen</td>\n",
              "      <td>citizen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>:</td>\n",
              "      <td>:</td>\n",
              "      <td>:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>before</td>\n",
              "      <td>befor</td>\n",
              "      <td>before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>we</td>\n",
              "      <td>we</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258328</th>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258329</th>\n",
              "      <td>but</td>\n",
              "      <td>but</td>\n",
              "      <td>but</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258330</th>\n",
              "      <td>who</td>\n",
              "      <td>who</td>\n",
              "      <td>who</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258331</th>\n",
              "      <td>comes</td>\n",
              "      <td>come</td>\n",
              "      <td>come</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258332</th>\n",
              "      <td>here</td>\n",
              "      <td>here</td>\n",
              "      <td>here</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>258333 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46a863c9-47fd-46a5-8cb0-fd9b0d9c413d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-46a863c9-47fd-46a5-8cb0-fd9b0d9c413d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-46a863c9-47fd-46a5-8cb0-fd9b0d9c413d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7244d317-6e6b-4b91-8797-4eba7973c964\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7244d317-6e6b-4b91-8797-4eba7973c964')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7244d317-6e6b-4b91-8797-4eba7973c964 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_e05d28c5-29e0-470e-88e5-896648720bd5\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_tokens')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_e05d28c5-29e0-470e-88e5-896648720bd5 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_tokens');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Token     Stem    Lemma\n",
              "0         first    first    first\n",
              "1       citizen  citizen  citizen\n",
              "2             :        :        :\n",
              "3        before    befor   before\n",
              "4            we       we       we\n",
              "...         ...      ...      ...\n",
              "258328        ?        ?        ?\n",
              "258329      but      but      but\n",
              "258330      who      who      who\n",
              "258331    comes     come     come\n",
              "258332     here     here     here\n",
              "\n",
              "[258333 rows x 3 columns]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Stemming + Lemmatizing\n",
        "import pandas as pd\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import nltk\n",
        "\n",
        "# Make sure these are downloaded\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "# Initialize stemmer and lemmatizer\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "df_tokens = pd.DataFrame({'Token': tokens_WP})\n",
        "\n",
        "# Apply stemming and lemmatization\n",
        "df_tokens['Stem'] = df_tokens['Token'].apply(lambda x: stemmer.stem(x))\n",
        "df_tokens['Lemma'] = df_tokens['Token'].apply(lambda x: lemmatizer.lemmatize(x))\n",
        "\n",
        "df_tokens\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "arWPyV_1GePx",
        "outputId": "126536be-99d7-404a-ac5f-e0fe903260af"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_tokens[df_tokens['Stem'] != df_tokens['Lemma']]\",\n  \"rows\": 30822,\n  \"fields\": [\n    {\n      \"column\": \"Token\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3129,\n        \"samples\": [\n          \"deities\",\n          \"leaning\",\n          \"strange\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Stem\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2319,\n        \"samples\": [\n          \"##bi\",\n          \"##igat\",\n          \"trumpet\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lemma\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2956,\n        \"samples\": [\n          \"adding\",\n          \"escaped\",\n          \"##els\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2ed4222b-9ac1-4c8f-b9af-7dc9dc0696a9\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Token</th>\n",
              "      <th>Stem</th>\n",
              "      <th>Lemma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>before</td>\n",
              "      <td>befor</td>\n",
              "      <td>before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>any</td>\n",
              "      <td>ani</td>\n",
              "      <td>any</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>resolved</td>\n",
              "      <td>resolv</td>\n",
              "      <td>resolved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>##mis</td>\n",
              "      <td>##mi</td>\n",
              "      <td>##mis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>resolved</td>\n",
              "      <td>resolv</td>\n",
              "      <td>resolved</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258284</th>\n",
              "      <td>wedding</td>\n",
              "      <td>wed</td>\n",
              "      <td>wedding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258312</th>\n",
              "      <td>occasion</td>\n",
              "      <td>occas</td>\n",
              "      <td>occasion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258314</th>\n",
              "      <td>revenge</td>\n",
              "      <td>reveng</td>\n",
              "      <td>revenge</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258322</th>\n",
              "      <td>thus</td>\n",
              "      <td>thu</td>\n",
              "      <td>thus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258326</th>\n",
              "      <td>as</td>\n",
              "      <td>as</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>30822 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2ed4222b-9ac1-4c8f-b9af-7dc9dc0696a9')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2ed4222b-9ac1-4c8f-b9af-7dc9dc0696a9 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2ed4222b-9ac1-4c8f-b9af-7dc9dc0696a9');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-ab817942-2ae6-4160-85de-6baa1a6f7938\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ab817942-2ae6-4160-85de-6baa1a6f7938')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-ab817942-2ae6-4160-85de-6baa1a6f7938 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           Token    Stem     Lemma\n",
              "3         before   befor    before\n",
              "6            any     ani       any\n",
              "25      resolved  resolv  resolved\n",
              "32         ##mis    ##mi     ##mis\n",
              "37      resolved  resolv  resolved\n",
              "...          ...     ...       ...\n",
              "258284   wedding     wed   wedding\n",
              "258312  occasion   occas  occasion\n",
              "258314   revenge  reveng   revenge\n",
              "258322      thus     thu      thus\n",
              "258326        as      as         a\n",
              "\n",
              "[30822 rows x 3 columns]"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Show words that have different lemmatized and stemmed versions\n",
        "df_tokens[df_tokens['Stem'] != df_tokens['Lemma']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U_ZuCDH1Gd0M"
      },
      "source": [
        "As we know, stem just truncates the words. It is faster but the stemmed chunks necessarily do not have meaning. Since we want to contnue the text in a meaningful way later, we will go with lemmatization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00MOCILZUcy9"
      },
      "source": [
        "Now we will do Lemmatizing based on part of speech. So, it understands that if ran was a verb it will convert it to run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXvMnHTydT8d",
        "outputId": "8daf099b-913e-454f-bef1-90bf108b2144"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Error loading punkt_eng: Package 'punkt_eng' not found in\n",
            "[nltk_data]     index\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt_eng')                        # for tokenizing\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger_eng')   # for POS tagging\n",
        "nltk.download('wordnet')                      # for lemmatization\n",
        "nltk.download('omw-1.4')                      # for lemmatizer language mappings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "AdmGHljwUo_K",
        "outputId": "e221f455-3cd4-4b91-9dd6-3c99034f0acd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_pos_lem"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-c9eb6c5d-2ef9-47d9-b801-1269f32b778e\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>Part of Speech</th>\n",
              "      <th>Lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>First</td>\n",
              "      <td>(First, RB)</td>\n",
              "      <td>First</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Citizen</td>\n",
              "      <td>(Citizen, NNP)</td>\n",
              "      <td>Citizen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>:</td>\n",
              "      <td>(:, :)</td>\n",
              "      <td>:</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Before</td>\n",
              "      <td>(Before, IN)</td>\n",
              "      <td>Before</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>we</td>\n",
              "      <td>(we, PRP)</td>\n",
              "      <td>we</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228773</th>\n",
              "      <td>?</td>\n",
              "      <td>(?, .)</td>\n",
              "      <td>?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228774</th>\n",
              "      <td>But</td>\n",
              "      <td>(But, CC)</td>\n",
              "      <td>But</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228775</th>\n",
              "      <td>who</td>\n",
              "      <td>(who, WP)</td>\n",
              "      <td>who</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228776</th>\n",
              "      <td>comes</td>\n",
              "      <td>(comes, VBZ)</td>\n",
              "      <td>come</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228777</th>\n",
              "      <td>here</td>\n",
              "      <td>(here, RB)</td>\n",
              "      <td>here</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>228778 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9eb6c5d-2ef9-47d9-b801-1269f32b778e')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c9eb6c5d-2ef9-47d9-b801-1269f32b778e button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c9eb6c5d-2ef9-47d9-b801-1269f32b778e');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-681b3581-e2d5-419a-89e2-4adc9be731f1\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-681b3581-e2d5-419a-89e2-4adc9be731f1')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-681b3581-e2d5-419a-89e2-4adc9be731f1 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_7bedb3a4-4659-474c-8e55-fad999f1033b\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_pos_lem')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_7bedb3a4-4659-474c-8e55-fad999f1033b button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_pos_lem');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "          Words  Part of Speech Lemmatized\n",
              "0         First     (First, RB)      First\n",
              "1       Citizen  (Citizen, NNP)    Citizen\n",
              "2             :          (:, :)          :\n",
              "3        Before    (Before, IN)     Before\n",
              "4            we       (we, PRP)         we\n",
              "...         ...             ...        ...\n",
              "228773        ?          (?, .)          ?\n",
              "228774      But       (But, CC)        But\n",
              "228775      who       (who, WP)        who\n",
              "228776    comes    (comes, VBZ)       come\n",
              "228777     here      (here, RB)       here\n",
              "\n",
              "[228778 rows x 3 columns]"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from nltk import pos_tag, word_tokenize\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "def get_wordnet_pos(treebank_tag):\n",
        "    if treebank_tag.startswith('J'):\n",
        "        return wordnet.ADJ\n",
        "    elif treebank_tag.startswith('V'):\n",
        "        return wordnet.VERB\n",
        "    elif treebank_tag.startswith('N'):\n",
        "        return wordnet.NOUN\n",
        "    elif treebank_tag.startswith('R'):\n",
        "        return wordnet.ADV\n",
        "    else:\n",
        "        return wordnet.NOUN  # default\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "text = dataset[0]['text']\n",
        "words = word_tokenize(text)\n",
        "tagged = pos_tag(words)\n",
        "lemmatized_tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in tagged]\n",
        "\n",
        "df_pos_lem = pd.DataFrame({'Words': words, 'Part of Speech': tagged,'Lemmatized': lemmatized_tokens})\n",
        "df_pos_lem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "6L7j82JZdu-e",
        "outputId": "7d2b2fc0-00d5-4282-805e-53843756821e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_pos_lem[df_pos_lem['Lemmatized'] != df_pos_lem['Words']]\",\n  \"rows\": 17971,\n  \"fields\": [\n    {\n      \"column\": \"Words\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3107,\n        \"samples\": [\n          \"envying\",\n          \"tapers\",\n          \"lays\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Part of Speech\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3664,\n        \"samples\": [\n          [\n            \"kneeling\",\n            \"VBG\"\n          ],\n          [\n            \"following\",\n            \"VBG\"\n          ],\n          [\n            \"pastures\",\n            \"NNS\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lemmatized\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2328,\n        \"samples\": [\n          \"ordain\",\n          \"forbid\",\n          \"delight\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-7bacf673-3220-4ae0-ad7b-6904d2f5be7c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Words</th>\n",
              "      <th>Part of Speech</th>\n",
              "      <th>Lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>are</td>\n",
              "      <td>(are, VBP)</td>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>resolved</td>\n",
              "      <td>(resolved, VBD)</td>\n",
              "      <td>resolve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>resolved</td>\n",
              "      <td>(resolved, VBN)</td>\n",
              "      <td>resolve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>is</td>\n",
              "      <td>(is, VBZ)</td>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>us</td>\n",
              "      <td>(us, PRP)</td>\n",
              "      <td>u</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228716</th>\n",
              "      <td>is</td>\n",
              "      <td>(is, VBZ)</td>\n",
              "      <td>be</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228741</th>\n",
              "      <td>apes</td>\n",
              "      <td>(apes, NNS)</td>\n",
              "      <td>ape</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228770</th>\n",
              "      <td>grieved</td>\n",
              "      <td>(grieved, VBN)</td>\n",
              "      <td>grieve</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228771</th>\n",
              "      <td>as</td>\n",
              "      <td>(as, IN)</td>\n",
              "      <td>a</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228776</th>\n",
              "      <td>comes</td>\n",
              "      <td>(comes, VBZ)</td>\n",
              "      <td>come</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>17971 rows × 3 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bacf673-3220-4ae0-ad7b-6904d2f5be7c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7bacf673-3220-4ae0-ad7b-6904d2f5be7c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7bacf673-3220-4ae0-ad7b-6904d2f5be7c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7f5b45e1-25ee-4701-ad25-c1f9df7d34a3\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7f5b45e1-25ee-4701-ad25-c1f9df7d34a3')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7f5b45e1-25ee-4701-ad25-c1f9df7d34a3 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "           Words   Part of Speech Lemmatized\n",
              "23           are       (are, VBP)         be\n",
              "25      resolved  (resolved, VBD)    resolve\n",
              "37      resolved  (resolved, VBN)    resolve\n",
              "48            is        (is, VBZ)         be\n",
              "67            us        (us, PRP)          u\n",
              "...          ...              ...        ...\n",
              "228716        is        (is, VBZ)         be\n",
              "228741      apes      (apes, NNS)        ape\n",
              "228770   grieved   (grieved, VBN)     grieve\n",
              "228771        as         (as, IN)          a\n",
              "228776     comes     (comes, VBZ)       come\n",
              "\n",
              "[17971 rows x 3 columns]"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check words that their memmatized is different\n",
        "df_pos_lem[df_pos_lem['Lemmatized'] != df_pos_lem['Words']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSttmfjOTlhK"
      },
      "source": [
        "### Noteabout differences between work tokens and phrases:\n",
        "\n",
        "Token-level training learns small syntax rules, grammar, and short dependencies\n",
        "\n",
        "Phrase-level training captures style, structure of speech, and broader semantic units"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UAWniCqfQozZ"
      },
      "source": [
        "### Generate sequences of varying length phrases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "p1EPWKtISOJc",
        "outputId": "f7e7faff-c993-4b36-8321-99d3884318c0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_phrases\",\n  \"rows\": 29982,\n  \"fields\": [\n    {\n      \"column\": \"Type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Phrase\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Raw\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25803,\n        \"samples\": [\n          \"indeed?\\n\\nTYRREL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lemmatized\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_phrases"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-2b0f5dbe-0a9a-4e1e-9511-c9664e583134\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Type</th>\n",
              "      <th>Raw</th>\n",
              "      <th>Lemmatized</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Phrase</td>\n",
              "      <td>First Citizen</td>\n",
              "      <td>[First, Citizen]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Phrase</td>\n",
              "      <td>Before we proceed any further</td>\n",
              "      <td>[Before, we, proceed, any, further]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Phrase</td>\n",
              "      <td>hear me speak.\\n\\nAll</td>\n",
              "      <td>[hear, me, speak, ., All]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Phrase</td>\n",
              "      <td>Speak</td>\n",
              "      <td>[Speak]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Phrase</td>\n",
              "      <td>speak.\\n\\nFirst Citizen</td>\n",
              "      <td>[speak, ., First, Citizen]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2b0f5dbe-0a9a-4e1e-9511-c9664e583134')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2b0f5dbe-0a9a-4e1e-9511-c9664e583134 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2b0f5dbe-0a9a-4e1e-9511-c9664e583134');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7d66d5f9-f734-4204-a676-b14a8eee39eb\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7d66d5f9-f734-4204-a676-b14a8eee39eb')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7d66d5f9-f734-4204-a676-b14a8eee39eb button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     Type                            Raw                           Lemmatized\n",
              "0  Phrase                  First Citizen                     [First, Citizen]\n",
              "1  Phrase  Before we proceed any further  [Before, we, proceed, any, further]\n",
              "2  Phrase          hear me speak.\\n\\nAll            [hear, me, speak, ., All]\n",
              "3  Phrase                          Speak                              [Speak]\n",
              "4  Phrase        speak.\\n\\nFirst Citizen           [speak, ., First, Citizen]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Create Phrase level sequences\n",
        "\n",
        "import re\n",
        "\n",
        "phrases = re.split(r'[,:;]', text)\n",
        "phrases = [p.strip() for p in phrases if len(p.strip()) > 0]\n",
        "\n",
        "# Lemmatize each phrase (with POS-aware)\n",
        "def lemmatize_phrase(phrase):\n",
        "    words = word_tokenize(phrase)\n",
        "    tagged = pos_tag(words)\n",
        "    return [lemmatizer.lemmatize(w, get_wordnet_pos(t)) for w, t in tagged]\n",
        "\n",
        "phrase_data = [{'Type': 'Phrase', 'Raw': p, 'Lemmatized': lemmatize_phrase(p)} for p in phrases]\n",
        "\n",
        "import pandas as pd\n",
        "df_phrases = pd.DataFrame(phrase_data)\n",
        "df_phrases.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "T0PcBThqe62b",
        "outputId": "f728e32b-1ae3-4fe1-e8b6-017f1d1458bc"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"changed[['Raw_Cleaned', 'Lemmatized_Joined']]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"Raw_Cleaned\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Resolved. resolved. First Citizen\",\n          \"and we'll have corn at our own price. Is't a verdict? All\",\n          \"you know Caius Marcius is chief enemy to the people. All\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Lemmatized_Joined\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Resolved. resolve. First Citizen\",\n          \"and we 'll have corn at our own price. Is't a verdict? All\",\n          \"you know Caius Marcius be chief enemy to the people. All\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-a75b9c7d-a46c-458f-8221-2731780c2aa7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Raw_Cleaned</th>\n",
              "      <th>Lemmatized_Joined</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>You are all resolved rather to die than to fam...</td>\n",
              "      <td>You be all resolve rather to die than to famis...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Resolved. resolved. First Citizen</td>\n",
              "      <td>Resolved. resolve. First Citizen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>you know Caius Marcius is chief enemy to the p...</td>\n",
              "      <td>you know Caius Marcius be chief enemy to the p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Let us kill him</td>\n",
              "      <td>Let u kill him</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>and we'll have corn at our own price. Is't a v...</td>\n",
              "      <td>and we 'll have corn at our own price. Is't a ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a75b9c7d-a46c-458f-8221-2731780c2aa7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a75b9c7d-a46c-458f-8221-2731780c2aa7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a75b9c7d-a46c-458f-8221-2731780c2aa7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7660582b-79e3-4089-8a8d-0556228ef9df\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7660582b-79e3-4089-8a8d-0556228ef9df')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7660582b-79e3-4089-8a8d-0556228ef9df button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "                                          Raw_Cleaned  \\\n",
              "5   You are all resolved rather to die than to fam...   \n",
              "6                   Resolved. resolved. First Citizen   \n",
              "8   you know Caius Marcius is chief enemy to the p...   \n",
              "11                                    Let us kill him   \n",
              "12  and we'll have corn at our own price. Is't a v...   \n",
              "\n",
              "                                    Lemmatized_Joined  \n",
              "5   You be all resolve rather to die than to famis...  \n",
              "6                    Resolved. resolve. First Citizen  \n",
              "8   you know Caius Marcius be chief enemy to the p...  \n",
              "11                                     Let u kill him  \n",
              "12  and we 'll have corn at our own price. Is't a ...  "
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Check when the Raw and Lemmatized version are different (Some words has changed)\n",
        "\n",
        "# Clean the Raw column: remove \\n, \\t, and strip spaces\n",
        "df_phrases['Raw_Cleaned'] = df_phrases['Raw'].apply(lambda x: ' '.join(x.split()))\n",
        "\n",
        "import re\n",
        "\n",
        "# Join tokens and fix spacing around punctuation\n",
        "def clean_lemmatized(tokens):\n",
        "    joined = ' '.join(tokens)\n",
        "    # Remove space before punctuation (e.g., 'word .' → 'word.')\n",
        "    cleaned = re.sub(r'\\s+([.,!?;:])', r'\\1', joined)\n",
        "    return cleaned\n",
        "\n",
        "df_phrases['Lemmatized_Joined'] = df_phrases['Lemmatized'].apply(clean_lemmatized)\n",
        "\n",
        "# Compare cleaned raw text with the lemmatized version\n",
        "changed = df_phrases[df_phrases['Raw_Cleaned'] != df_phrases['Lemmatized_Joined']]\n",
        "\n",
        "# Show the differences\n",
        "changed[['Raw_Cleaned', 'Lemmatized_Joined']].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twc6mXUHhS_F"
      },
      "source": [
        "Based on this observation, I realized Lemmatizing is case snsitive\n",
        "\n",
        "* Lowercase = verb or noun (contextualized)\n",
        "* Capitalized = likely a proper noun or unknown, so it might not lemmatize it.\n",
        "\n",
        "But on the other hand we are working with sentances data so cases are important so I decided not to make a change."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oq9ben-rebAq",
        "outputId": "ddeeb088-9c6c-49ff-a559-1638cce421bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak. All:\n",
            "Speak, speak. First Citizen:\n",
            "You are all resolved rather to die than to famish? All:\n",
            "Resolved. resolved.\n",
            "First Citizen : Before we proceed any further , hear me speak . All : Speak , speak . First Citizen : You be all resolve rather to die than to famish ? All : Resolved . resolve .\n"
          ]
        }
      ],
      "source": [
        "#Create Long phrases\n",
        "\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sentences = sent_tokenize(text)\n",
        "chunks = [' '.join(sentences[i:i+5]) for i in range(0, len(sentences), 5)]\n",
        "\n",
        "chunk_data = [{'Type': 'LongPhrase', 'Raw': chunk, 'Lemmatized': lemmatize_phrase(chunk)} for chunk in chunks]\n",
        "df_long = pd.DataFrame(chunk_data)\n",
        "\n",
        "print(df_long['Raw'][0])\n",
        "print(' '.join(df_long['Lemmatized'][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2in_4N6Ey8Y3"
      },
      "source": [
        "# RNN architectures"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQNdqZds7n-c"
      },
      "source": [
        "**RNNs (Recurrent Neural Networks)** are the simplest form of sequence models. They process input sequentially, maintaining a hidden state that captures previous information. However, they struggle with long-range dependencies due to the vanishing gradient problem, which makes them less effective at capturing deeper context in text generation.\n",
        "\n",
        "**LSTMs (Long Short-Term Memory networks)** are an improved version of RNNs. They include memory cells and gating mechanisms (input, output, forget gates) that allow them to retain information over longer sequences. This makes them much better suited for text generation and prediction, especially when understanding structure and long-term context is important.\n",
        "\n",
        "**GRUs (Gated Recurrent Units)** are similar to LSTMs but have a simpler architecture with fewer gates (reset and update gates). They are computationally lighter and often perform comparably to LSTMs on many tasks. For text generation, GRUs strike a good balance between performance and training efficiency, especially when long sequences are involved but not excessively complex."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TlJMK_2lLsYP"
      },
      "source": [
        "### Vanilla RNN (Bidirectional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS4Lcee8MIb4"
      },
      "source": [
        "Vanilla RNN: Simple and fast for small tasks, good as a baseline.\n",
        "\n",
        "Bidirectional: Captures both past and future context, especially helpful in NLP.\n",
        "\n",
        "No dropout: We'll start clean; dropout will be added later\n",
        "\n",
        "rnn_out[:, -1, :]: We use the last timestep output to feed into the classifier.\n",
        "\n",
        "hidden_dim * 2: Due to bidirectionality (forward + backward)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "rvbRsQEn4MYs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class VanillaRNNModel_Bi(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(VanillaRNNModel_Bi, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.rnn = nn.RNN(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)                      # (B, S, E)\n",
        "        rnn_out, _ = self.rnn(embedded)                   # (B, S, H*2)\n",
        "        return self.fc(rnn_out)                            # (B, S, V)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEJ0xea7MBzK"
      },
      "source": [
        "### LSTM (Bidirectional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTNY3VsrMWFW"
      },
      "source": [
        "LSTM: Handles long-term dependencies better than RNN via gates (input, forget, output).\n",
        "\n",
        "Bidirectional: Essential in many NLP tasks where context matters on both ends (e.g., sentiment).\n",
        "\n",
        "Hidden size doubled for bidirectional=True.\n",
        "\n",
        "Output at last timestep used — could also try mean/attention pooling later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "DBwc6jivMeTw"
      },
      "outputs": [],
      "source": [
        "class LSTMModel_Bi(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, num_layers=1):\n",
        "        super(LSTMModel_Bi, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers=num_layers,\n",
        "                            batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)  # *2 for bidirectional\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, _ = self.lstm(embedded)\n",
        "        return self.fc(output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4v1lmAq2MiQm"
      },
      "source": [
        "### GRU (Bidirectional)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6VP4D9doMib1"
      },
      "source": [
        "GRU: Simplified version of LSTM (fewer gates), faster to train, similar performance.\n",
        "\n",
        "Often performs well on medium-sized datasets.\n",
        "\n",
        "Same architecture as LSTM, just the recurrent unit changes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "c268f9BBMxSh"
      },
      "outputs": [],
      "source": [
        "class GRUModel_Bi(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
        "        super(GRUModel_Bi, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)                      # (B, S, E)\n",
        "        output, _ = self.gru(embedded)                   # (B, S, H*2)\n",
        "        return self.fc(output)                            # (B, S, V)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N4z6rcAB0QJ4"
      },
      "source": [
        "# Train and Optimize Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMD7aQJ2RhFU"
      },
      "source": [
        "### Splitting data in text train validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrQogf4HQ380"
      },
      "source": [
        "We decided to have training set as well to first tune the hyperparameters and then test on test data and measure preplexity\n",
        "\n",
        "*Note*: In language modeling (including RNN-based text generation), the target (y) is just the next word in the sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "LGD7v3SIRqWv"
      },
      "outputs": [],
      "source": [
        "def split_data_tokens(tokens, seq_len, train_ratio=0.8, val_ratio=0.1):\n",
        "    total = len(tokens)\n",
        "    train_end = int(total * train_ratio)\n",
        "    val_end = int(total * (train_ratio + val_ratio))\n",
        "\n",
        "    train_tokens = tokens[:train_end]\n",
        "    val_tokens = tokens[train_end:val_end]\n",
        "    test_tokens = tokens[val_end:]\n",
        "\n",
        "    def create_sequences(token_list):\n",
        "        inputs, targets = [], []\n",
        "        for i in range(len(token_list) - seq_len):\n",
        "            inputs.append(token_list[i:i+seq_len])\n",
        "            targets.append(token_list[i+1:i+seq_len+1])\n",
        "        return inputs, targets\n",
        "\n",
        "    X_train, y_train = create_sequences(train_tokens)\n",
        "    X_val, y_val = create_sequences(val_tokens)\n",
        "    X_test, y_test = create_sequences(test_tokens)\n",
        "\n",
        "    return X_train, y_train, X_val, y_val, X_test, y_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47IsKJfn7ZVA"
      },
      "source": [
        "### Parametrs\n",
        "\n",
        "**embedding_dim:** The size of the dense vector used to represent each word.\n",
        "\n",
        "Words are encoded into continuous vector space so the model can learn semantic meaning.\n",
        "\n",
        "It is used in the output size of the nn.Embedding layer.\n",
        "\n",
        "**hidden_dim:** The size of the hidden state inside the RNN, LSTM, or GRU.\n",
        "It is used in RNN layer's internal computation and controls how much information the RNN can store at each step.\n",
        "\n",
        "**optimizer** : The algorithm that updates your model’s weights during training, based on the gradients computed from loss.\n",
        "\n",
        "It controls how the model learns — how fast, how stable, and whether it converges at all.\n",
        "It is used on every training step — right after .backward().\n",
        "\n",
        "**Gradien Clipping**\n",
        "\n",
        "nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "This is the line doing gradient clipping in our train model function.\n",
        "\n",
        "Pass information recursively over time steps\n",
        "\n",
        "Multiply gradients over and over (risking exploding or vanishing gradients)\n",
        "\n",
        "Are often deeper in the time dimension than feedforward nets\n",
        "\n",
        "Without clipping, gradients might explode after just a few epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFNHg0oENHeb"
      },
      "source": [
        "### Vanilla RNN (Bidirectional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "j100rBLIM-_F"
      },
      "outputs": [],
      "source": [
        "# === TRAINING ===\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=10, clip=5):\n",
        "    model.to(device)\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X)\n",
        "            loss = criterion(output.view(-1, output.shape[-1]), y.view(-1))\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                output = model(X)\n",
        "                loss = criterion(output.view(-1, output.shape[-1]), y.view(-1))\n",
        "                val_loss += loss.item()\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_perplexity = torch.exp(torch.tensor(avg_val_loss))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}, Val Perplexity = {val_perplexity:.2f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "\n",
        "    return best_val_loss, val_perplexity.item(), best_model_state\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "_w1Q_Yr8_btH"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# === MAIN LOOP ===\n",
        "def run_experiments_on_dataset(name, df, token_col, seq_len=50, batch_size=64):\n",
        "    print(f\"\\n📘 Running experiments on dataset: {name}\")\n",
        "\n",
        "    # Flatten token list\n",
        "    if isinstance(df[token_col].iloc[0], list):\n",
        "        tokens = list(itertools.chain.from_iterable(df[token_col]))\n",
        "    else:\n",
        "        tokens = df[token_col].tolist()\n",
        "\n",
        "    # Build vocab\n",
        "    vocab = sorted(set(tokens))\n",
        "    stoi = {w: i for i, w in enumerate(vocab)}\n",
        "    indexed_tokens = [stoi[t] for t in tokens]\n",
        "    vocab_size = len(stoi)\n",
        "\n",
        "    # Split data\n",
        "    X_train, y_train, X_val, y_val, _, _ = split_data_tokens(indexed_tokens, seq_len)\n",
        "\n",
        "    # Datasets & loaders\n",
        "    train_dataset = TensorDataset(\n",
        "    torch.tensor(X_train, dtype=torch.long),\n",
        "    torch.tensor(y_train, dtype=torch.long))\n",
        "\n",
        "    val_dataset = TensorDataset(\n",
        "    torch.tensor(X_val, dtype=torch.long),\n",
        "    torch.tensor(y_val, dtype=torch.long))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Hyperparams\n",
        "    embedding_dims = [86, 128]\n",
        "    hidden_dims = [64, 128]\n",
        "    optimizers = ['adam', 'rmsprop', 'sgd']\n",
        "    results = []\n",
        "    best_overall_loss = float('inf')\n",
        "    best_overall_model = None\n",
        "    best_config = None\n",
        "\n",
        "    for embedding_dim in embedding_dims:\n",
        "        for hidden_dim in hidden_dims:\n",
        "            for opt_name in optimizers:\n",
        "                print(f\"\\n🔧 Config: embed={embedding_dim}, hidden={hidden_dim}, opt={opt_name.upper()}\")\n",
        "                model = VanillaRNNModel_Bi(vocab_size, embedding_dim, hidden_dim, vocab_size)\n",
        "\n",
        "                if opt_name == 'adam':\n",
        "                    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "                elif opt_name == 'rmsprop':\n",
        "                    optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001)\n",
        "                elif opt_name == 'sgd':\n",
        "                    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "\n",
        "                criterion = nn.CrossEntropyLoss()\n",
        "                device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "                val_loss, val_ppl, model_state = train_model(\n",
        "                    model, train_loader, val_loader, optimizer, criterion, device\n",
        "                )\n",
        "\n",
        "                results.append((embedding_dim, hidden_dim, opt_name, val_loss, val_ppl))\n",
        "\n",
        "                if val_loss < best_overall_loss:\n",
        "                    best_overall_loss = val_loss\n",
        "                    best_overall_model = model_state\n",
        "                    best_config = (embedding_dim, hidden_dim, opt_name)\n",
        "\n",
        "    print(f\"\\n✅ BEST CONFIG FOR {name.upper()}: embed={best_config[0]}, hidden={best_config[1]}, opt={best_config[2].upper()} | Val Loss: {best_overall_loss:.4f}\")\n",
        "    return results, best_config, best_overall_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "gpaPV_ZP_TCE",
        "outputId": "6591eea6-a93c-42af-ab60-367ac7e57d44"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📘 Running experiments on dataset: df_tokens\n",
            "\n",
            "🔧 Config: embed=86, hidden=64, opt=ADAM\n",
            "Epoch 1: Train Loss = 0.7671, Val Loss = 0.8396, Val Perplexity = 2.32\n",
            "Epoch 2: Train Loss = 0.0990, Val Loss = 0.8105, Val Perplexity = 2.25\n",
            "Epoch 3: Train Loss = 0.0905, Val Loss = 0.8121, Val Perplexity = 2.25\n",
            "Epoch 4: Train Loss = 0.0870, Val Loss = 0.8195, Val Perplexity = 2.27\n",
            "Epoch 5: Train Loss = 0.0846, Val Loss = 0.8405, Val Perplexity = 2.32\n",
            "Epoch 6: Train Loss = 0.0826, Val Loss = 0.8610, Val Perplexity = 2.37\n",
            "Epoch 7: Train Loss = 0.0810, Val Loss = 0.8805, Val Perplexity = 2.41\n",
            "Epoch 8: Train Loss = 0.0795, Val Loss = 0.8894, Val Perplexity = 2.43\n",
            "Epoch 9: Train Loss = 0.0782, Val Loss = 0.9134, Val Perplexity = 2.49\n",
            "Epoch 10: Train Loss = 0.0770, Val Loss = 0.9229, Val Perplexity = 2.52\n",
            "\n",
            "🔧 Config: embed=86, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.5289, Val Loss = 0.8072, Val Perplexity = 2.24\n",
            "Epoch 2: Train Loss = 0.0935, Val Loss = 0.7006, Val Perplexity = 2.01\n",
            "Epoch 3: Train Loss = 0.0913, Val Loss = 0.6658, Val Perplexity = 1.95\n",
            "Epoch 4: Train Loss = 0.0907, Val Loss = 0.6616, Val Perplexity = 1.94\n",
            "Epoch 5: Train Loss = 0.0902, Val Loss = 0.6699, Val Perplexity = 1.95\n",
            "Epoch 6: Train Loss = 0.0898, Val Loss = 0.6805, Val Perplexity = 1.97\n",
            "Epoch 7: Train Loss = 0.0892, Val Loss = 0.6883, Val Perplexity = 1.99\n",
            "Epoch 8: Train Loss = 0.0887, Val Loss = 0.7012, Val Perplexity = 2.02\n",
            "Epoch 9: Train Loss = 0.0881, Val Loss = 0.7141, Val Perplexity = 2.04\n",
            "Epoch 10: Train Loss = 0.0875, Val Loss = 0.7258, Val Perplexity = 2.07\n",
            "\n",
            "🔧 Config: embed=86, hidden=64, opt=SGD\n",
            "Epoch 1: Train Loss = 6.6092, Val Loss = 5.2558, Val Perplexity = 191.67\n",
            "Epoch 2: Train Loss = 4.8514, Val Loss = 4.5286, Val Perplexity = 92.63\n",
            "Epoch 3: Train Loss = 4.2828, Val Loss = 4.1321, Val Perplexity = 62.31\n",
            "Epoch 4: Train Loss = 3.9316, Val Loss = 3.8690, Val Perplexity = 47.89\n",
            "Epoch 5: Train Loss = 3.6780, Val Loss = 3.6686, Val Perplexity = 39.20\n",
            "Epoch 6: Train Loss = 3.4762, Val Loss = 3.5053, Val Perplexity = 33.29\n",
            "Epoch 7: Train Loss = 3.3082, Val Loss = 3.3672, Val Perplexity = 29.00\n",
            "Epoch 8: Train Loss = 3.1647, Val Loss = 3.2487, Val Perplexity = 25.76\n",
            "Epoch 9: Train Loss = 3.0402, Val Loss = 3.1450, Val Perplexity = 23.22\n",
            "Epoch 10: Train Loss = 2.9306, Val Loss = 3.0534, Val Perplexity = 21.19\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=ADAM\n",
            "Epoch 1: Train Loss = 0.4375, Val Loss = 0.7173, Val Perplexity = 2.05\n",
            "Epoch 2: Train Loss = 0.0932, Val Loss = 0.7028, Val Perplexity = 2.02\n",
            "Epoch 3: Train Loss = 0.0875, Val Loss = 0.7334, Val Perplexity = 2.08\n",
            "Epoch 4: Train Loss = 0.0832, Val Loss = 0.7668, Val Perplexity = 2.15\n",
            "Epoch 5: Train Loss = 0.0798, Val Loss = 0.7988, Val Perplexity = 2.22\n",
            "Epoch 6: Train Loss = 0.0768, Val Loss = 0.8429, Val Perplexity = 2.32\n",
            "Epoch 7: Train Loss = 0.0743, Val Loss = 0.8670, Val Perplexity = 2.38\n",
            "Epoch 8: Train Loss = 0.0720, Val Loss = 0.8875, Val Perplexity = 2.43\n",
            "Epoch 9: Train Loss = 0.0700, Val Loss = 0.9078, Val Perplexity = 2.48\n",
            "Epoch 10: Train Loss = 0.0682, Val Loss = 0.9281, Val Perplexity = 2.53\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.2764, Val Loss = 0.6333, Val Perplexity = 1.88\n",
            "Epoch 2: Train Loss = 0.0921, Val Loss = 0.5908, Val Perplexity = 1.81\n",
            "Epoch 3: Train Loss = 0.0905, Val Loss = 0.5885, Val Perplexity = 1.80\n",
            "Epoch 4: Train Loss = 0.0891, Val Loss = 0.6110, Val Perplexity = 1.84\n",
            "Epoch 5: Train Loss = 0.0878, Val Loss = 0.6170, Val Perplexity = 1.85\n",
            "Epoch 6: Train Loss = 0.0865, Val Loss = 0.6297, Val Perplexity = 1.88\n",
            "Epoch 7: Train Loss = 0.0852, Val Loss = 0.6440, Val Perplexity = 1.90\n",
            "Epoch 8: Train Loss = 0.0840, Val Loss = 0.6543, Val Perplexity = 1.92\n",
            "Epoch 9: Train Loss = 0.0827, Val Loss = 0.6724, Val Perplexity = 1.96\n",
            "Epoch 10: Train Loss = 0.0814, Val Loss = 0.6840, Val Perplexity = 1.98\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=SGD\n",
            "Epoch 1: Train Loss = 6.0124, Val Loss = 4.7196, Val Perplexity = 112.12\n",
            "Epoch 2: Train Loss = 4.2812, Val Loss = 3.9987, Val Perplexity = 54.53\n",
            "Epoch 3: Train Loss = 3.7228, Val Loss = 3.6216, Val Perplexity = 37.40\n",
            "Epoch 4: Train Loss = 3.3722, Val Loss = 3.3578, Val Perplexity = 28.73\n",
            "Epoch 5: Train Loss = 3.1090, Val Loss = 3.1523, Val Perplexity = 23.39\n",
            "Epoch 6: Train Loss = 2.8992, Val Loss = 2.9851, Val Perplexity = 19.79\n",
            "Epoch 7: Train Loss = 2.7269, Val Loss = 2.8460, Val Perplexity = 17.22\n",
            "Epoch 8: Train Loss = 2.5820, Val Loss = 2.7274, Val Perplexity = 15.29\n",
            "Epoch 9: Train Loss = 2.4574, Val Loss = 2.6249, Val Perplexity = 13.80\n",
            "Epoch 10: Train Loss = 2.3485, Val Loss = 2.5346, Val Perplexity = 12.61\n",
            "\n",
            "🔧 Config: embed=128, hidden=64, opt=ADAM\n",
            "Epoch 1: Train Loss = 0.7505, Val Loss = 0.8197, Val Perplexity = 2.27\n",
            "Epoch 2: Train Loss = 0.0985, Val Loss = 0.7901, Val Perplexity = 2.20\n",
            "Epoch 3: Train Loss = 0.0902, Val Loss = 0.7991, Val Perplexity = 2.22\n",
            "Epoch 4: Train Loss = 0.0867, Val Loss = 0.8073, Val Perplexity = 2.24\n",
            "Epoch 5: Train Loss = 0.0842, Val Loss = 0.8291, Val Perplexity = 2.29\n",
            "Epoch 6: Train Loss = 0.0821, Val Loss = 0.8553, Val Perplexity = 2.35\n",
            "Epoch 7: Train Loss = 0.0803, Val Loss = 0.8691, Val Perplexity = 2.38\n",
            "Epoch 8: Train Loss = 0.0788, Val Loss = 0.8906, Val Perplexity = 2.44\n",
            "Epoch 9: Train Loss = 0.0774, Val Loss = 0.8968, Val Perplexity = 2.45\n",
            "Epoch 10: Train Loss = 0.0761, Val Loss = 0.9209, Val Perplexity = 2.51\n",
            "\n",
            "🔧 Config: embed=128, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.5125, Val Loss = 0.7880, Val Perplexity = 2.20\n",
            "Epoch 2: Train Loss = 0.0928, Val Loss = 0.6852, Val Perplexity = 1.98\n",
            "Epoch 3: Train Loss = 0.0907, Val Loss = 0.6650, Val Perplexity = 1.94\n",
            "Epoch 4: Train Loss = 0.0900, Val Loss = 0.6720, Val Perplexity = 1.96\n",
            "Epoch 5: Train Loss = 0.0893, Val Loss = 0.6720, Val Perplexity = 1.96\n",
            "Epoch 6: Train Loss = 0.0886, Val Loss = 0.6813, Val Perplexity = 1.98\n",
            "Epoch 7: Train Loss = 0.0879, Val Loss = 0.7011, Val Perplexity = 2.02\n",
            "Epoch 8: Train Loss = 0.0872, Val Loss = 0.7096, Val Perplexity = 2.03\n",
            "Epoch 9: Train Loss = 0.0866, Val Loss = 0.7251, Val Perplexity = 2.06\n",
            "Epoch 10: Train Loss = 0.0859, Val Loss = 0.7393, Val Perplexity = 2.09\n",
            "\n",
            "🔧 Config: embed=128, hidden=64, opt=SGD\n",
            "Epoch 1: Train Loss = 6.6586, Val Loss = 5.2553, Val Perplexity = 191.58\n",
            "Epoch 2: Train Loss = 4.8383, Val Loss = 4.5035, Val Perplexity = 90.33\n",
            "Epoch 3: Train Loss = 4.2546, Val Loss = 4.0999, Val Perplexity = 60.33\n",
            "Epoch 4: Train Loss = 3.8963, Val Loss = 3.8332, Val Perplexity = 46.21\n",
            "Epoch 5: Train Loss = 3.6376, Val Loss = 3.6310, Val Perplexity = 37.75\n",
            "Epoch 6: Train Loss = 3.4322, Val Loss = 3.4665, Val Perplexity = 32.03\n",
            "Epoch 7: Train Loss = 3.2616, Val Loss = 3.3276, Val Perplexity = 27.87\n",
            "Epoch 8: Train Loss = 3.1163, Val Loss = 3.2078, Val Perplexity = 24.72\n",
            "Epoch 9: Train Loss = 2.9908, Val Loss = 3.1033, Val Perplexity = 22.27\n",
            "Epoch 10: Train Loss = 2.8806, Val Loss = 3.0110, Val Perplexity = 20.31\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=ADAM\n",
            "Epoch 1: Train Loss = 0.4286, Val Loss = 0.7017, Val Perplexity = 2.02\n",
            "Epoch 2: Train Loss = 0.0920, Val Loss = 0.6881, Val Perplexity = 1.99\n",
            "Epoch 3: Train Loss = 0.0866, Val Loss = 0.6908, Val Perplexity = 2.00\n",
            "Epoch 4: Train Loss = 0.0822, Val Loss = 0.7219, Val Perplexity = 2.06\n",
            "Epoch 5: Train Loss = 0.0788, Val Loss = 0.7525, Val Perplexity = 2.12\n",
            "Epoch 6: Train Loss = 0.0757, Val Loss = 0.7844, Val Perplexity = 2.19\n",
            "Epoch 7: Train Loss = 0.0731, Val Loss = 0.8085, Val Perplexity = 2.24\n",
            "Epoch 8: Train Loss = 0.0707, Val Loss = 0.8282, Val Perplexity = 2.29\n",
            "Epoch 9: Train Loss = 0.0687, Val Loss = 0.8578, Val Perplexity = 2.36\n",
            "Epoch 10: Train Loss = 0.0668, Val Loss = 0.8955, Val Perplexity = 2.45\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.2675, Val Loss = 0.6093, Val Perplexity = 1.84\n",
            "Epoch 2: Train Loss = 0.0914, Val Loss = 0.5770, Val Perplexity = 1.78\n",
            "Epoch 3: Train Loss = 0.0896, Val Loss = 0.5793, Val Perplexity = 1.78\n",
            "Epoch 4: Train Loss = 0.0881, Val Loss = 0.5995, Val Perplexity = 1.82\n",
            "Epoch 5: Train Loss = 0.0865, Val Loss = 0.6169, Val Perplexity = 1.85\n",
            "Epoch 6: Train Loss = 0.0849, Val Loss = 0.6259, Val Perplexity = 1.87\n",
            "Epoch 7: Train Loss = 0.0835, Val Loss = 0.6348, Val Perplexity = 1.89\n",
            "Epoch 8: Train Loss = 0.0822, Val Loss = 0.6469, Val Perplexity = 1.91\n",
            "Epoch 9: Train Loss = 0.0809, Val Loss = 0.6567, Val Perplexity = 1.93\n",
            "Epoch 10: Train Loss = 0.0796, Val Loss = 0.6624, Val Perplexity = 1.94\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=SGD\n",
            "Epoch 1: Train Loss = 6.0304, Val Loss = 4.6930, Val Perplexity = 109.19\n",
            "Epoch 2: Train Loss = 4.2463, Val Loss = 3.9716, Val Perplexity = 53.07\n",
            "Epoch 3: Train Loss = 3.6835, Val Loss = 3.5953, Val Perplexity = 36.43\n",
            "Epoch 4: Train Loss = 3.3312, Val Loss = 3.3296, Val Perplexity = 27.93\n",
            "Epoch 5: Train Loss = 3.0687, Val Loss = 3.1243, Val Perplexity = 22.74\n",
            "Epoch 6: Train Loss = 2.8613, Val Loss = 2.9587, Val Perplexity = 19.27\n",
            "Epoch 7: Train Loss = 2.6914, Val Loss = 2.8220, Val Perplexity = 16.81\n",
            "Epoch 8: Train Loss = 2.5481, Val Loss = 2.7057, Val Perplexity = 14.96\n",
            "Epoch 9: Train Loss = 2.4245, Val Loss = 2.6046, Val Perplexity = 13.53\n",
            "Epoch 10: Train Loss = 2.3161, Val Loss = 2.5154, Val Perplexity = 12.37\n",
            "\n",
            "✅ BEST CONFIG FOR DF_TOKENS: embed=128, hidden=128, opt=RMSPROP | Val Loss: 0.5770\n",
            "\n",
            "📘 Running experiments on dataset: df_pos_lem\n",
            "\n",
            "🔧 Config: embed=86, hidden=64, opt=ADAM\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-bc05bc2db36a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mresults_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiments_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df_tokens\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Lemma\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mresults_pos_lem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_pos_lem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_pos_lem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiments_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df_pos_lem\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_pos_lem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Lemmatized\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mresults_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_phrases\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiments_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df_phrases\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_phrases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Lemmatized\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mresults_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_long\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_experiments_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"df_long\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_long\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Lemmatized\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-64e8e180377c>\u001b[0m in \u001b[0;36mrun_experiments_on_dataset\u001b[0;34m(name, df, token_col, seq_len, batch_size)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cuda'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 val_loss, val_ppl, model_state = train_model(\n\u001b[0m\u001b[1;32m     60\u001b[0m                     \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 )\n",
            "\u001b[0;32m<ipython-input-30-77d08050d2f2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, device, epochs, clip)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "#Run it on lemmatized tokens\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "import itertools\n",
        "\n",
        "results_tokens, best_tokens, model_tokens = run_experiments_on_dataset(\"df_tokens\", df_tokens, token_col=\"Lemma\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o8v4ZKlx8YaS"
      },
      "source": [
        "The code has an error cause I stopped it to make some chnages and re-run it more efficiently with fewer smart choices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "pk3EN2YAb_46"
      },
      "outputs": [],
      "source": [
        "torch.save(model_tokens,\"/content/drive/My Drive/Colab Notebooks/Models/RNN_model_tokens.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gcaaAeCCJBHL"
      },
      "source": [
        "**Interpretation of the results**\n",
        "\n",
        "SGD performed poorly overall. Even the training loss remained high, indicating that the optimizer struggled to converge. As a result, we will not continue using SGD in further experiments.\n",
        "\n",
        "For ADAM, the training loss dropped rapidly in all cases, but the validation loss began to increase, which is a clear sign of overfitting. However, this issue is not necessarily due to the optimizer itself. It's possible that the model is too complex for the data, leading to high variance.\n",
        "\n",
        "Higher embedding dimensions consistently resulted in better validation loss. This makes sense because in Shakespeare-style text generation, the language is:\n",
        "\n",
        "* Rich in stylistic variation\n",
        "\n",
        "* Heavily dependent on context and syntactic structure\n",
        "\n",
        "A larger embedding size allows the model to capture these subtle nuances more effectively, leading to improved performance.\n",
        "\n",
        "--------------\n",
        "\n",
        "*Next*\n",
        "We will only use ADAM and RMSprop for other architectures.\n",
        "For solving the overfitting issue we will add a weight decay to\n",
        "We will add early stopping to the model cause we see in some cases after 5 epoch there were no change in the loss.\n",
        "\n",
        "-----------------\n",
        "\n",
        "So I will choose RMSPROP as the optimizer cbecause in all 3 best models that was the optimizer.\n",
        "\n",
        "But because of the following fact I will explore two different numbers for both embedding and hidden layers.\n",
        "\n",
        "* Changing from tokens to POS lemmatization or phrasing changes the\n",
        "nature of your input representation. The vocabulary distribution, context patterns, and sequence structure may shift. Embedding layers may capture different linguistic patterns, and deeper hidden layers might respond differently to richer syntactic signals.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V81xvdHzUeAM"
      },
      "source": [
        "**Choose the better parameters + early stopping and rerun it for other ways of tokenizing and phrasing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "cdEo7bqcY_VD"
      },
      "outputs": [],
      "source": [
        "# Update training model to add early stopping and patience\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=10, clip=5, early_stopping=False, patience=3):\n",
        "    model.to(device)\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X)\n",
        "            loss = criterion(output.view(-1, output.shape[-1]), y.view(-1))\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                output = model(X)\n",
        "                loss = criterion(output.view(-1, output.shape[-1]), y.view(-1))\n",
        "                val_loss += loss.item()\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_perplexity = torch.exp(torch.tensor(avg_val_loss))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}, Val Perplexity = {val_perplexity:.2f}\")\n",
        "\n",
        "        # Check for improvement\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        # Early stopping trigger\n",
        "        if early_stopping and epochs_without_improvement >= patience:\n",
        "            print(f\"⏹️ Early stopping triggered after {epoch+1} epochs.\")\n",
        "            break\n",
        "\n",
        "    return best_val_loss, val_perplexity.item(), best_model_state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "OJ5kn_wPYFcM"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "def run_experiments_on_dataset(name, df, token_col, seq_len=50, batch_size=64, weight_decay=0.0, patience=3):\n",
        "    print(f\"\\n📘 Running experiments on dataset: {name}\")\n",
        "\n",
        "    # Flatten token list\n",
        "    if isinstance(df[token_col].iloc[0], list):\n",
        "        tokens = list(itertools.chain.from_iterable(df[token_col]))\n",
        "    else:\n",
        "        tokens = df[token_col].tolist()\n",
        "\n",
        "    # Build vocab\n",
        "    vocab = sorted(set(tokens))\n",
        "    stoi = {w: i for i, w in enumerate(vocab)}\n",
        "    indexed_tokens = [stoi[t] for t in tokens]\n",
        "    vocab_size = len(stoi)\n",
        "\n",
        "    # Split data\n",
        "    X_train, y_train, X_val, y_val, _, _ = split_data_tokens(indexed_tokens, seq_len)\n",
        "\n",
        "    # Datasets & loaders\n",
        "    train_dataset = TensorDataset(\n",
        "        torch.tensor(X_train, dtype=torch.long),\n",
        "        torch.tensor(y_train, dtype=torch.long))\n",
        "\n",
        "    val_dataset = TensorDataset(\n",
        "        torch.tensor(X_val, dtype=torch.long),\n",
        "        torch.tensor(y_val, dtype=torch.long))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Hyperparams\n",
        "    embedding_dims = [86, 128]\n",
        "    hidden_dims = [64, 128]\n",
        "    results = []\n",
        "    best_overall_loss = float('inf')\n",
        "    best_overall_model = None\n",
        "    best_config = None\n",
        "\n",
        "    for embedding_dim in embedding_dims:\n",
        "        for hidden_dim in hidden_dims:\n",
        "            print(f\"\\n🔧 Config: embed={embedding_dim}, hidden={hidden_dim}, opt=RMSPROP\")\n",
        "            model = VanillaRNNModel_Bi(vocab_size, embedding_dim, hidden_dim, vocab_size)\n",
        "\n",
        "            optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=weight_decay)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "            val_loss, val_ppl, model_state = train_model(\n",
        "                model, train_loader, val_loader, optimizer, criterion, device,\n",
        "                early_stopping=True, patience=patience\n",
        "            )\n",
        "\n",
        "            results.append((embedding_dim, hidden_dim, 'rmsprop', val_loss, val_ppl))\n",
        "\n",
        "            if val_loss < best_overall_loss:\n",
        "                best_overall_loss = val_loss\n",
        "                best_overall_model = model_state\n",
        "                best_config = (embedding_dim, hidden_dim, 'rmsprop')\n",
        "\n",
        "    print(f\"\\n✅ BEST CONFIG FOR {name.upper()}: embed={best_config[0]}, hidden={best_config[1]}, opt=RMSPROP | Val Loss: {best_overall_loss:.4f}, Perplexity: {np.exp(best_overall_loss):.2f}\")\n",
        "    return results, best_config, best_overall_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYXDAQbYaDwn",
        "outputId": "ff2c0112-fcb3-4ac7-b10a-4e8f99320694"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "#Connect to google\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yn7RujpCUR7n",
        "outputId": "12064887-0040-483c-fa98-88ef8f150c80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training model on Tokens lemmatized based on Part of Speech\n",
            "\n",
            "📘 Running experiments on dataset: df_pos_lem\n",
            "\n",
            "🔧 Config: embed=86, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.6665, Val Loss = 1.3056, Val Perplexity = 3.69\n",
            "Epoch 2: Train Loss = 0.0993, Val Loss = 1.1848, Val Perplexity = 3.27\n",
            "Epoch 3: Train Loss = 0.0961, Val Loss = 1.1468, Val Perplexity = 3.15\n",
            "Epoch 4: Train Loss = 0.0955, Val Loss = 1.1384, Val Perplexity = 3.12\n",
            "Epoch 5: Train Loss = 0.0952, Val Loss = 1.1548, Val Perplexity = 3.17\n",
            "Epoch 6: Train Loss = 0.0949, Val Loss = 1.1839, Val Perplexity = 3.27\n",
            "Epoch 7: Train Loss = 0.0945, Val Loss = 1.2121, Val Perplexity = 3.36\n",
            "⏹️ Early stopping triggered after 7 epochs.\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.3387, Val Loss = 1.0238, Val Perplexity = 2.78\n",
            "Epoch 2: Train Loss = 0.0972, Val Loss = 0.9472, Val Perplexity = 2.58\n",
            "Epoch 3: Train Loss = 0.0957, Val Loss = 0.9800, Val Perplexity = 2.66\n",
            "Epoch 4: Train Loss = 0.0945, Val Loss = 1.0137, Val Perplexity = 2.76\n",
            "Epoch 5: Train Loss = 0.0933, Val Loss = 1.0486, Val Perplexity = 2.85\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.6535, Val Loss = 1.3064, Val Perplexity = 3.69\n",
            "Epoch 2: Train Loss = 0.0988, Val Loss = 1.2061, Val Perplexity = 3.34\n",
            "Epoch 3: Train Loss = 0.0958, Val Loss = 1.1876, Val Perplexity = 3.28\n",
            "Epoch 4: Train Loss = 0.0950, Val Loss = 1.1864, Val Perplexity = 3.28\n",
            "Epoch 5: Train Loss = 0.0945, Val Loss = 1.2125, Val Perplexity = 3.36\n",
            "Epoch 6: Train Loss = 0.0939, Val Loss = 1.2404, Val Perplexity = 3.46\n",
            "Epoch 7: Train Loss = 0.0933, Val Loss = 1.2782, Val Perplexity = 3.59\n",
            "⏹️ Early stopping triggered after 7 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.3360, Val Loss = 1.0304, Val Perplexity = 2.80\n",
            "Epoch 2: Train Loss = 0.0966, Val Loss = 0.9830, Val Perplexity = 2.67\n",
            "Epoch 3: Train Loss = 0.0948, Val Loss = 1.0039, Val Perplexity = 2.73\n",
            "Epoch 4: Train Loss = 0.0933, Val Loss = 1.0292, Val Perplexity = 2.80\n",
            "Epoch 5: Train Loss = 0.0918, Val Loss = 1.0538, Val Perplexity = 2.87\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "✅ BEST CONFIG FOR DF_POS_LEM: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.9472, Perplexity: 2.58\n",
            "Training model on Short Phrases (Lemmatized)\n",
            "\n",
            "📘 Running experiments on dataset: df_phrases\n",
            "\n",
            "🔧 Config: embed=86, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.7898, Val Loss = 1.5523, Val Perplexity = 4.72\n",
            "Epoch 2: Train Loss = 0.1081, Val Loss = 1.4279, Val Perplexity = 4.17\n",
            "Epoch 3: Train Loss = 0.1037, Val Loss = 1.3787, Val Perplexity = 3.97\n",
            "Epoch 4: Train Loss = 0.1029, Val Loss = 1.3816, Val Perplexity = 3.98\n",
            "Epoch 5: Train Loss = 0.1026, Val Loss = 1.3979, Val Perplexity = 4.05\n",
            "Epoch 6: Train Loss = 0.1022, Val Loss = 1.4287, Val Perplexity = 4.17\n",
            "⏹️ Early stopping triggered after 6 epochs.\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.3893, Val Loss = 1.2501, Val Perplexity = 3.49\n",
            "Epoch 2: Train Loss = 0.1047, Val Loss = 1.1677, Val Perplexity = 3.21\n",
            "Epoch 3: Train Loss = 0.1029, Val Loss = 1.1644, Val Perplexity = 3.20\n",
            "Epoch 4: Train Loss = 0.1015, Val Loss = 1.1853, Val Perplexity = 3.27\n",
            "Epoch 5: Train Loss = 0.1001, Val Loss = 1.2404, Val Perplexity = 3.46\n",
            "Epoch 6: Train Loss = 0.0987, Val Loss = 1.2591, Val Perplexity = 3.52\n",
            "⏹️ Early stopping triggered after 6 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.7781, Val Loss = 1.5469, Val Perplexity = 4.70\n",
            "Epoch 2: Train Loss = 0.1074, Val Loss = 1.4099, Val Perplexity = 4.10\n",
            "Epoch 3: Train Loss = 0.1031, Val Loss = 1.3317, Val Perplexity = 3.79\n",
            "Epoch 4: Train Loss = 0.1022, Val Loss = 1.3277, Val Perplexity = 3.77\n",
            "Epoch 5: Train Loss = 0.1017, Val Loss = 1.3538, Val Perplexity = 3.87\n",
            "Epoch 6: Train Loss = 0.1011, Val Loss = 1.3828, Val Perplexity = 3.99\n",
            "Epoch 7: Train Loss = 0.1005, Val Loss = 1.4237, Val Perplexity = 4.15\n",
            "⏹️ Early stopping triggered after 7 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.3783, Val Loss = 1.2394, Val Perplexity = 3.45\n",
            "Epoch 2: Train Loss = 0.1037, Val Loss = 1.1271, Val Perplexity = 3.09\n",
            "Epoch 3: Train Loss = 0.1017, Val Loss = 1.1397, Val Perplexity = 3.13\n",
            "Epoch 4: Train Loss = 0.0999, Val Loss = 1.1693, Val Perplexity = 3.22\n",
            "Epoch 5: Train Loss = 0.0981, Val Loss = 1.1939, Val Perplexity = 3.30\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "✅ BEST CONFIG FOR DF_PHRASES: embed=128, hidden=128, opt=RMSPROP | Val Loss: 1.1271, Perplexity: 3.09\n",
            "Training model on Long Phrases (Lemmatized)\n",
            "\n",
            "📘 Running experiments on dataset: df_long\n",
            "\n",
            "🔧 Config: embed=86, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.6753, Val Loss = 1.3213, Val Perplexity = 3.75\n",
            "Epoch 2: Train Loss = 0.0994, Val Loss = 1.2047, Val Perplexity = 3.34\n",
            "Epoch 3: Train Loss = 0.0960, Val Loss = 1.1589, Val Perplexity = 3.19\n",
            "Epoch 4: Train Loss = 0.0954, Val Loss = 1.1550, Val Perplexity = 3.17\n",
            "Epoch 5: Train Loss = 0.0951, Val Loss = 1.1677, Val Perplexity = 3.21\n",
            "Epoch 6: Train Loss = 0.0948, Val Loss = 1.1891, Val Perplexity = 3.28\n",
            "Epoch 7: Train Loss = 0.0944, Val Loss = 1.2241, Val Perplexity = 3.40\n",
            "⏹️ Early stopping triggered after 7 epochs.\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.3420, Val Loss = 1.0450, Val Perplexity = 2.84\n",
            "Epoch 2: Train Loss = 0.0972, Val Loss = 0.9701, Val Perplexity = 2.64\n",
            "Epoch 3: Train Loss = 0.0957, Val Loss = 0.9864, Val Perplexity = 2.68\n",
            "Epoch 4: Train Loss = 0.0945, Val Loss = 1.0340, Val Perplexity = 2.81\n",
            "Epoch 5: Train Loss = 0.0933, Val Loss = 1.0763, Val Perplexity = 2.93\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.6629, Val Loss = 1.3193, Val Perplexity = 3.74\n",
            "Epoch 2: Train Loss = 0.0988, Val Loss = 1.2189, Val Perplexity = 3.38\n",
            "Epoch 3: Train Loss = 0.0957, Val Loss = 1.1860, Val Perplexity = 3.27\n",
            "Epoch 4: Train Loss = 0.0949, Val Loss = 1.1830, Val Perplexity = 3.26\n",
            "Epoch 5: Train Loss = 0.0944, Val Loss = 1.2007, Val Perplexity = 3.32\n",
            "Epoch 6: Train Loss = 0.0939, Val Loss = 1.2287, Val Perplexity = 3.42\n",
            "Epoch 7: Train Loss = 0.0934, Val Loss = 1.2584, Val Perplexity = 3.52\n",
            "⏹️ Early stopping triggered after 7 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.3318, Val Loss = 1.0493, Val Perplexity = 2.86\n",
            "Epoch 2: Train Loss = 0.0967, Val Loss = 0.9829, Val Perplexity = 2.67\n",
            "Epoch 3: Train Loss = 0.0949, Val Loss = 1.0050, Val Perplexity = 2.73\n",
            "Epoch 4: Train Loss = 0.0934, Val Loss = 1.0327, Val Perplexity = 2.81\n",
            "Epoch 5: Train Loss = 0.0918, Val Loss = 1.0654, Val Perplexity = 2.90\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "✅ BEST CONFIG FOR DF_LONG: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.9701, Perplexity: 2.64\n"
          ]
        }
      ],
      "source": [
        "#Run it on lemmatized based on part of speech and short and long phrases\n",
        "\n",
        "import torch\n",
        "\n",
        "print(\"Training model on Tokens lemmatized based on Part of Speech\")\n",
        "results_pos_lem, best_pos_lem, model_pos_lem = run_experiments_on_dataset(\"df_pos_lem\", df_pos_lem, token_col=\"Lemmatized\")\n",
        "torch.save(model_pos_lem, \"/content/drive/My Drive/Colab Notebooks/Models/RNN_model_pos_lem.pth\")\n",
        "\n",
        "print(\"Training model on Short Phrases (Lemmatized)\")\n",
        "results_phrases, best_phrases, model_phrases = run_experiments_on_dataset(\"df_phrases\", df_phrases, token_col=\"Lemmatized\")\n",
        "torch.save(model_phrases, \"/content/drive/My Drive/Colab Notebooks/Models/RNN_model_phrases.pth\")\n",
        "\n",
        "print(\"Training model on Long Phrases (Lemmatized)\")\n",
        "results_long, best_long, model_long = run_experiments_on_dataset(\"df_long\", df_long, token_col=\"Lemmatized\")\n",
        "torch.save(model_long, \"/content/drive/My Drive/Colab Notebooks/Models/RNN_model_long.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKkr56JdwgIv"
      },
      "source": [
        "**Summary of best model performances on training sets:**\n",
        "\n",
        "(We will use these for test sets from the same input. Bu input I mean the type of tokenizing is different)\n",
        "\n",
        "\n",
        "✅ BEST CONFIG FOR DF_TOKENS: embed=128, hidden=128, opt=RMSPROP | Val Loss: 0.5770, Val Perplexity = 1.78\n",
        "\n",
        "✅ BEST CONFIG FOR DF_POS_LEM: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.9472, Perplexity: 2.58\n",
        "\n",
        "✅ BEST CONFIG FOR DF_PHRASES: embed=128, hidden=128, opt=RMSPROP | Val Loss: 1.1271, Perplexity: 3.09\n",
        "\n",
        "✅ BEST CONFIG FOR DF_LONG: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.9701, Perplexity: 2.64\n",
        "\n",
        "\n",
        "---------------------\n",
        "**Takeways**\n",
        "\n",
        "* We see that modeling on Tokens has the lowest cost. Token-level\n",
        "inputs are easiest to model for this task. Predicting the next token is relatively straightforward with good performance.\n",
        "\n",
        "* Perplexity is exponential of the loss:\n",
        "A perplexity of 1.78 (tokens) means the model is very confident about the next token prediction.\n",
        "\n",
        "* Lemmatization reduces variation, but POS-aware lemmatization can lead to less natural token sequences (e.g., verbs, nouns, etc., might appear out of typical natural order). So, POS lemmatization is useful for certain NLP tasks (e.g., reducing vocabulary), but here, it introduces a bit more complexity for sequence prediction.\n",
        "\n",
        "* It was surprising to me that we predicted longer phrases, compared to short phrases with lower perplexity, meaning less confusion.\n",
        "\n",
        "* This could be the reson behind it:Longer phrases often follow grammatical patterns, such as subject–verb–object or preposition–noun structures. These regularities can actually make predictions more consistent across examples. They also may contain more context and can be more semantically stable.\n",
        "\n",
        "* So I decided to limit training the other structures only on df_tokens and df_long. This way we will have a token prediction and a phrase prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGDbN8HrNJwH"
      },
      "source": [
        "### LSTM (Bidirectional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "54t7gqWXUEGV"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "def run_experiments_on_dataset(name, df, token_col, seq_len=50, batch_size=64, weight_decay=0.0, patience=3):\n",
        "    print(f\"\\n📘 Running experiments on dataset: {name}\")\n",
        "\n",
        "    # Flatten token list\n",
        "    if isinstance(df[token_col].iloc[0], list):\n",
        "        tokens = list(itertools.chain.from_iterable(df[token_col]))\n",
        "    else:\n",
        "        tokens = df[token_col].tolist()\n",
        "\n",
        "    # Build vocab\n",
        "    vocab = sorted(set(tokens))\n",
        "    stoi = {w: i for i, w in enumerate(vocab)}\n",
        "    indexed_tokens = [stoi[t] for t in tokens]\n",
        "    vocab_size = len(stoi)\n",
        "\n",
        "    # Split data\n",
        "    X_train, y_train, X_val, y_val, _, _ = split_data_tokens(indexed_tokens, seq_len)\n",
        "\n",
        "    # Datasets & loaders\n",
        "    train_dataset = TensorDataset(\n",
        "        torch.tensor(X_train, dtype=torch.long),\n",
        "        torch.tensor(y_train, dtype=torch.long))\n",
        "\n",
        "    val_dataset = TensorDataset(\n",
        "        torch.tensor(X_val, dtype=torch.long),\n",
        "        torch.tensor(y_val, dtype=torch.long))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Hyperparams\n",
        "    embedding_dims = [86, 128]\n",
        "    hidden_dims = [64, 128]\n",
        "    results = []\n",
        "    best_overall_loss = float('inf')\n",
        "    best_overall_model = None\n",
        "    best_config = None\n",
        "\n",
        "    for embedding_dim in embedding_dims:\n",
        "        for hidden_dim in hidden_dims:\n",
        "            print(f\"\\n🔧 Config: embed={embedding_dim}, hidden={hidden_dim}, opt=RMSPROP\")\n",
        "            # We only changed the model\n",
        "            model = LSTMModel_Bi(vocab_size, embedding_dim, hidden_dim, vocab_size)\n",
        "\n",
        "            optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=weight_decay)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "            val_loss, val_ppl, model_state = train_model(\n",
        "                model, train_loader, val_loader, optimizer, criterion, device,\n",
        "                early_stopping=True, patience=patience\n",
        "            )\n",
        "\n",
        "            results.append((embedding_dim, hidden_dim, 'rmsprop', val_loss, val_ppl))\n",
        "\n",
        "            if val_loss < best_overall_loss:\n",
        "                best_overall_loss = val_loss\n",
        "                best_overall_model = model_state\n",
        "                best_config = (embedding_dim, hidden_dim, 'rmsprop')\n",
        "\n",
        "    print(f\"\\n✅ BEST CONFIG FOR {name.upper()}: embed={best_config[0]}, hidden={best_config[1]}, opt=RMSPROP | Val Loss: {best_overall_loss:.4f}, Perplexity: {np.exp(best_overall_loss):.2f}\")\n",
        "    return results, best_config, best_overall_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fL5mq0kz9_k",
        "outputId": "1254ea14-3f53-4fe4-9df1-7cefa23748d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📘 Running experiments on dataset: df_tokens\n",
            "\n",
            "🔧 Config: embed=86, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.8779, Val Loss = 1.0537, Val Perplexity = 2.87\n",
            "Epoch 2: Train Loss = 0.0955, Val Loss = 0.9899, Val Perplexity = 2.69\n",
            "Epoch 3: Train Loss = 0.0903, Val Loss = 1.0288, Val Perplexity = 2.80\n",
            "Epoch 4: Train Loss = 0.0884, Val Loss = 1.0776, Val Perplexity = 2.94\n",
            "Epoch 5: Train Loss = 0.0872, Val Loss = 1.1141, Val Perplexity = 3.05\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.4310, Val Loss = 0.7474, Val Perplexity = 2.11\n",
            "Epoch 2: Train Loss = 0.0888, Val Loss = 0.7223, Val Perplexity = 2.06\n",
            "Epoch 3: Train Loss = 0.0862, Val Loss = 0.7510, Val Perplexity = 2.12\n",
            "Epoch 4: Train Loss = 0.0840, Val Loss = 0.7652, Val Perplexity = 2.15\n",
            "Epoch 5: Train Loss = 0.0821, Val Loss = 0.7789, Val Perplexity = 2.18\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.8646, Val Loss = 1.0802, Val Perplexity = 2.95\n",
            "Epoch 2: Train Loss = 0.0946, Val Loss = 1.0010, Val Perplexity = 2.72\n",
            "Epoch 3: Train Loss = 0.0891, Val Loss = 1.0379, Val Perplexity = 2.82\n",
            "Epoch 4: Train Loss = 0.0871, Val Loss = 1.0991, Val Perplexity = 3.00\n",
            "Epoch 5: Train Loss = 0.0858, Val Loss = 1.1708, Val Perplexity = 3.22\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.4195, Val Loss = 0.7911, Val Perplexity = 2.21\n",
            "Epoch 2: Train Loss = 0.0879, Val Loss = 0.7663, Val Perplexity = 2.15\n",
            "Epoch 3: Train Loss = 0.0851, Val Loss = 0.7974, Val Perplexity = 2.22\n",
            "Epoch 4: Train Loss = 0.0829, Val Loss = 0.8269, Val Perplexity = 2.29\n",
            "Epoch 5: Train Loss = 0.0810, Val Loss = 0.8411, Val Perplexity = 2.32\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "✅ BEST CONFIG FOR DF_TOKENS: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.7223, Perplexity: 2.06\n",
            "\n",
            "📘 Running experiments on dataset: df_long\n",
            "\n",
            "🔧 Config: embed=86, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 1.1008, Val Loss = 1.6274, Val Perplexity = 5.09\n",
            "Epoch 2: Train Loss = 0.1025, Val Loss = 1.5054, Val Perplexity = 4.51\n",
            "Epoch 3: Train Loss = 0.0947, Val Loss = 1.5752, Val Perplexity = 4.83\n",
            "Epoch 4: Train Loss = 0.0925, Val Loss = 1.6645, Val Perplexity = 5.28\n",
            "Epoch 5: Train Loss = 0.0913, Val Loss = 1.7454, Val Perplexity = 5.73\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.5307, Val Loss = 1.2620, Val Perplexity = 3.53\n",
            "Epoch 2: Train Loss = 0.0930, Val Loss = 1.3140, Val Perplexity = 3.72\n",
            "Epoch 3: Train Loss = 0.0903, Val Loss = 1.4254, Val Perplexity = 4.16\n",
            "Epoch 4: Train Loss = 0.0882, Val Loss = 1.4623, Val Perplexity = 4.32\n",
            "⏹️ Early stopping triggered after 4 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 1.0767, Val Loss = 1.6934, Val Perplexity = 5.44\n",
            "Epoch 2: Train Loss = 0.1026, Val Loss = 1.5598, Val Perplexity = 4.76\n",
            "Epoch 3: Train Loss = 0.0942, Val Loss = 1.6281, Val Perplexity = 5.09\n",
            "Epoch 4: Train Loss = 0.0916, Val Loss = 1.7257, Val Perplexity = 5.62\n",
            "Epoch 5: Train Loss = 0.0901, Val Loss = 1.8241, Val Perplexity = 6.20\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.5307, Val Loss = 1.3050, Val Perplexity = 3.69\n",
            "Epoch 2: Train Loss = 0.0917, Val Loss = 1.3667, Val Perplexity = 3.92\n",
            "Epoch 3: Train Loss = 0.0889, Val Loss = 1.4457, Val Perplexity = 4.25\n",
            "Epoch 4: Train Loss = 0.0867, Val Loss = 1.5086, Val Perplexity = 4.52\n",
            "⏹️ Early stopping triggered after 4 epochs.\n",
            "\n",
            "✅ BEST CONFIG FOR DF_LONG: embed=86, hidden=128, opt=RMSPROP | Val Loss: 1.2620, Perplexity: 3.53\n"
          ]
        }
      ],
      "source": [
        "#Run it only lemmatized tokens and long phrases to capture both word by word and phrase text prediction\n",
        "\n",
        "results_tokens, best_tokens, model_tokens = run_experiments_on_dataset(\"df_tokens\", df_tokens, token_col=\"Lemma\")\n",
        "torch.save(model_tokens, \"/content/drive/My Drive/Colab Notebooks/Models/LSTM_model_tokens.pth\")\n",
        "\n",
        "results_long, best_long, model_long = run_experiments_on_dataset(\"df_long\", df_long, token_col=\"Lemmatized\")\n",
        "torch.save(model_long, \"/content/drive/My Drive/Colab Notebooks/Models/LSTM_model_long.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jku3EDM-opj"
      },
      "source": [
        "**Comparing RNN and LSTM results**\n",
        "\n",
        "We know that LSTMs have more parameters due to their gating mechanisms (input, output, forget gates). So even with the same hidden size, an LSTM has more learnable weights than an RNN.\n",
        "\n",
        "So, it can fit the training data faster (lower train loss). But also has a higher risk of overfitting, especially if the dataset is not large or diverse enough.\n",
        "\n",
        "But in my results, this is mostly not the case.\n",
        "\n",
        "✅ RNN: BEST CONFIG FOR DF_TOKENS: embed=128, hidden=128, opt=RMSPROP | Val Loss: 0.5770, Val Perplexity = 1.78\n",
        "\n",
        "✅ LSTM: BEST CONFIG FOR DF_TOKENS: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.7223, Perplexity: 2.06\n",
        "\n",
        "We see that for df_tokens as I checked the best models they have similar train tests (0.08) but RNN had lower validation cost and perplexity so it outperformed LSTM.\n",
        "\n",
        "**LSTM’s strength is modeling long-range dependencies.**\n",
        "\n",
        "So  I assumed that on longer phrases it will have a better performance.\n",
        "\n",
        "✅ RNN: BEST CONFIG FOR DF_LONG: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.9701, Perplexity: 2.64\n",
        "\n",
        "✅ LSTM: BEST CONFIG FOR DF_LONG: embed=86, hidden=128, opt=RMSPROP | Val Loss: 1.2620, Perplexity: 3.53\n",
        "\n",
        "But as wee even with pharses RNN was better then complexity of LSTM might just be unnecessary overhead without payoff.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VAkgk9XNJ8f"
      },
      "source": [
        "### GRU (Bidirectional)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "oM2PMYpw1G-Q"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "def run_experiments_on_dataset(name, df, token_col, seq_len=50, batch_size=64, weight_decay=0.0, patience=3):\n",
        "    print(f\"\\n📘 Running experiments on dataset: {name}\")\n",
        "\n",
        "    # Flatten token list\n",
        "    if isinstance(df[token_col].iloc[0], list):\n",
        "        tokens = list(itertools.chain.from_iterable(df[token_col]))\n",
        "    else:\n",
        "        tokens = df[token_col].tolist()\n",
        "\n",
        "    # Build vocab\n",
        "    vocab = sorted(set(tokens))\n",
        "    stoi = {w: i for i, w in enumerate(vocab)}\n",
        "    indexed_tokens = [stoi[t] for t in tokens]\n",
        "    vocab_size = len(stoi)\n",
        "\n",
        "    # Split data\n",
        "    X_train, y_train, X_val, y_val, _, _ = split_data_tokens(indexed_tokens, seq_len)\n",
        "\n",
        "    # Datasets & loaders\n",
        "    train_dataset = TensorDataset(\n",
        "        torch.tensor(X_train, dtype=torch.long),\n",
        "        torch.tensor(y_train, dtype=torch.long))\n",
        "\n",
        "    val_dataset = TensorDataset(\n",
        "        torch.tensor(X_val, dtype=torch.long),\n",
        "        torch.tensor(y_val, dtype=torch.long))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Hyperparams\n",
        "    embedding_dims = [86, 128]\n",
        "    hidden_dims = [64, 128]\n",
        "    results = []\n",
        "    best_overall_loss = float('inf')\n",
        "    best_overall_model = None\n",
        "    best_config = None\n",
        "\n",
        "    for embedding_dim in embedding_dims:\n",
        "        for hidden_dim in hidden_dims:\n",
        "            print(f\"\\n🔧 Config: embed={embedding_dim}, hidden={hidden_dim}, opt=RMSPROP\")\n",
        "            # We only changed the model\n",
        "            model = GRUModel_Bi(vocab_size, embedding_dim, hidden_dim, vocab_size)\n",
        "\n",
        "            optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=weight_decay)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "            val_loss, val_ppl, model_state = train_model(\n",
        "                model, train_loader, val_loader, optimizer, criterion, device,\n",
        "                early_stopping=True, patience=patience\n",
        "            )\n",
        "\n",
        "            results.append((embedding_dim, hidden_dim, 'rmsprop', val_loss, val_ppl))\n",
        "\n",
        "            if val_loss < best_overall_loss:\n",
        "                best_overall_loss = val_loss\n",
        "                best_overall_model = model_state\n",
        "                best_config = (embedding_dim, hidden_dim, 'rmsprop')\n",
        "\n",
        "    print(f\"\\n✅ BEST CONFIG FOR {name.upper()}: embed={best_config[0]}, hidden={best_config[1]}, opt=RMSPROP | Val Loss: {best_overall_loss:.4f}, Perplexity: {np.exp(best_overall_loss):.2f}\")\n",
        "    return results, best_config, best_overall_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SvNtwXeb_v7l",
        "outputId": "31286ba4-c39c-4af3-fb48-c8fc18e15011"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📘 Running experiments on dataset: df_tokens\n",
            "\n",
            "🔧 Config: embed=86, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.7464, Val Loss = 0.9373, Val Perplexity = 2.55\n",
            "Epoch 2: Train Loss = 0.0936, Val Loss = 0.8210, Val Perplexity = 2.27\n",
            "Epoch 3: Train Loss = 0.0901, Val Loss = 0.7946, Val Perplexity = 2.21\n",
            "Epoch 4: Train Loss = 0.0890, Val Loss = 0.7885, Val Perplexity = 2.20\n",
            "Epoch 5: Train Loss = 0.0883, Val Loss = 0.7901, Val Perplexity = 2.20\n",
            "Epoch 6: Train Loss = 0.0876, Val Loss = 0.7950, Val Perplexity = 2.21\n",
            "Epoch 7: Train Loss = 0.0870, Val Loss = 0.8080, Val Perplexity = 2.24\n",
            "⏹️ Early stopping triggered after 7 epochs.\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.3284, Val Loss = 0.6200, Val Perplexity = 1.86\n",
            "Epoch 2: Train Loss = 0.0906, Val Loss = 0.6072, Val Perplexity = 1.84\n",
            "Epoch 3: Train Loss = 0.0886, Val Loss = 0.6326, Val Perplexity = 1.88\n",
            "Epoch 4: Train Loss = 0.0866, Val Loss = 0.6619, Val Perplexity = 1.94\n",
            "Epoch 5: Train Loss = 0.0848, Val Loss = 0.6793, Val Perplexity = 1.97\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.7408, Val Loss = 1.0266, Val Perplexity = 2.79\n",
            "Epoch 2: Train Loss = 0.0943, Val Loss = 0.9293, Val Perplexity = 2.53\n",
            "Epoch 3: Train Loss = 0.0897, Val Loss = 0.8914, Val Perplexity = 2.44\n",
            "Epoch 4: Train Loss = 0.0881, Val Loss = 0.8858, Val Perplexity = 2.42\n",
            "Epoch 5: Train Loss = 0.0871, Val Loss = 0.8885, Val Perplexity = 2.43\n",
            "Epoch 6: Train Loss = 0.0864, Val Loss = 0.8975, Val Perplexity = 2.45\n",
            "Epoch 7: Train Loss = 0.0856, Val Loss = 0.8997, Val Perplexity = 2.46\n",
            "⏹️ Early stopping triggered after 7 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.3356, Val Loss = 0.6601, Val Perplexity = 1.93\n",
            "Epoch 2: Train Loss = 0.0891, Val Loss = 0.6458, Val Perplexity = 1.91\n",
            "Epoch 3: Train Loss = 0.0868, Val Loss = 0.6518, Val Perplexity = 1.92\n",
            "Epoch 4: Train Loss = 0.0847, Val Loss = 0.6735, Val Perplexity = 1.96\n",
            "Epoch 5: Train Loss = 0.0827, Val Loss = 0.6967, Val Perplexity = 2.01\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "✅ BEST CONFIG FOR DF_TOKENS: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.6072, Perplexity: 1.84\n",
            "\n",
            "📘 Running experiments on dataset: df_long\n",
            "\n",
            "🔧 Config: embed=86, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.9113, Val Loss = 1.4812, Val Perplexity = 4.40\n",
            "Epoch 2: Train Loss = 0.0999, Val Loss = 1.3660, Val Perplexity = 3.92\n",
            "Epoch 3: Train Loss = 0.0953, Val Loss = 1.3579, Val Perplexity = 3.89\n",
            "Epoch 4: Train Loss = 0.0941, Val Loss = 1.3591, Val Perplexity = 3.89\n",
            "Epoch 5: Train Loss = 0.0935, Val Loss = 1.3925, Val Perplexity = 4.02\n",
            "Epoch 6: Train Loss = 0.0929, Val Loss = 1.4005, Val Perplexity = 4.06\n",
            "⏹️ Early stopping triggered after 6 epochs.\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.4093, Val Loss = 1.0801, Val Perplexity = 2.95\n",
            "Epoch 2: Train Loss = 0.0955, Val Loss = 1.0581, Val Perplexity = 2.88\n",
            "Epoch 3: Train Loss = 0.0936, Val Loss = 1.1017, Val Perplexity = 3.01\n",
            "Epoch 4: Train Loss = 0.0918, Val Loss = 1.1568, Val Perplexity = 3.18\n",
            "Epoch 5: Train Loss = 0.0899, Val Loss = 1.2159, Val Perplexity = 3.37\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=64, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.9870, Val Loss = 1.6870, Val Perplexity = 5.40\n",
            "Epoch 2: Train Loss = 0.1043, Val Loss = 1.5812, Val Perplexity = 4.86\n",
            "Epoch 3: Train Loss = 0.0958, Val Loss = 1.5471, Val Perplexity = 4.70\n",
            "Epoch 4: Train Loss = 0.0933, Val Loss = 1.5337, Val Perplexity = 4.64\n",
            "Epoch 5: Train Loss = 0.0919, Val Loss = 1.5461, Val Perplexity = 4.69\n",
            "Epoch 6: Train Loss = 0.0908, Val Loss = 1.5721, Val Perplexity = 4.82\n",
            "Epoch 7: Train Loss = 0.0899, Val Loss = 1.5939, Val Perplexity = 4.92\n",
            "⏹️ Early stopping triggered after 7 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.4185, Val Loss = 1.1144, Val Perplexity = 3.05\n",
            "Epoch 2: Train Loss = 0.0942, Val Loss = 1.0801, Val Perplexity = 2.95\n",
            "Epoch 3: Train Loss = 0.0919, Val Loss = 1.0952, Val Perplexity = 2.99\n",
            "Epoch 4: Train Loss = 0.0899, Val Loss = 1.1586, Val Perplexity = 3.19\n",
            "Epoch 5: Train Loss = 0.0879, Val Loss = 1.2191, Val Perplexity = 3.38\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "✅ BEST CONFIG FOR DF_LONG: embed=86, hidden=128, opt=RMSPROP | Val Loss: 1.0581, Perplexity: 2.88\n"
          ]
        }
      ],
      "source": [
        "#Run it only lemmatized tokens and long phrases to capture both word by word and phrase text prediction\n",
        "\n",
        "results_tokens, best_tokens, model_tokens = run_experiments_on_dataset(\"df_tokens\", df_tokens, token_col=\"Lemma\")\n",
        "torch.save(model_tokens, \"/content/drive/My Drive/Colab Notebooks/Models/GRU_model_tokens.pth\")\n",
        "\n",
        "results_long, best_long, model_long = run_experiments_on_dataset(\"df_long\", df_long, token_col=\"Lemmatized\")\n",
        "torch.save(model_long, \"/content/drive/My Drive/Colab Notebooks/Models/GRU_model_long.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "panXs1frLAlj"
      },
      "source": [
        "**Comparing with RNN**\n",
        "\n",
        "✅ RNN: BEST CONFIG FOR DF_TOKENS: embed=128, hidden=128, opt=RMSPROP | Val Loss: 0.5770, Val Perplexity = 1.78\n",
        "\n",
        "✅ GRU: BEST CONFIG FOR DF_TOKENS: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.6072, Perplexity: 1.84\n",
        "\n",
        "**GRU’s strength is modeling long-range dependencies.**\n",
        "\n",
        "So  I assumed that on longer phrases it will have a better performance.\n",
        "\n",
        "✅ RNN: BEST CONFIG FOR DF_LONG: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.9701, Perplexity: 2.64\n",
        "\n",
        "✅ GRU: BEST CONFIG FOR DF_LONG: embed=86, hidden=128, opt=RMSPROP | Val Loss: 1.0581, Perplexity: 2.88\n",
        "\n",
        "Gru performance is still alittle worse than RNN but it is very close so we will some changes to see if we can use its full potential.\n",
        "\n",
        "------------------\n",
        "\n",
        "*Changes*:\n",
        "\n",
        "GRUs can be a bit more sensitive to learning rate so we will go with lr=0.0005\n",
        "\n",
        "The current seq_len=50 might not give the GRU enough temporal depth to leverage its memory. We will test 100. This increases how much context the model sees in each training sample. GRUs shine when they can track dependencies across longer sequences.\n",
        "\n",
        "hidden=128 was better in all scenarios. So we son't change that anymore but keep changing the embedding.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "fSs-iavYMjxX"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import itertools\n",
        "import numpy as np\n",
        "\n",
        "def run_experiments_on_dataset(name, df, token_col, seq_len=100, batch_size=64, weight_decay=0.0, patience=3):\n",
        "    print(f\"\\n📘 Running experiments on dataset: {name}\")\n",
        "\n",
        "    # Flatten token list\n",
        "    if isinstance(df[token_col].iloc[0], list):\n",
        "        tokens = list(itertools.chain.from_iterable(df[token_col]))\n",
        "    else:\n",
        "        tokens = df[token_col].tolist()\n",
        "\n",
        "    # Build vocab\n",
        "    vocab = sorted(set(tokens))\n",
        "    stoi = {w: i for i, w in enumerate(vocab)}\n",
        "    indexed_tokens = [stoi[t] for t in tokens]\n",
        "    vocab_size = len(stoi)\n",
        "\n",
        "    # Split data\n",
        "    X_train, y_train, X_val, y_val, _, _ = split_data_tokens(indexed_tokens, seq_len)\n",
        "\n",
        "    # Datasets & loaders\n",
        "    train_dataset = TensorDataset(\n",
        "        torch.tensor(X_train, dtype=torch.long),\n",
        "        torch.tensor(y_train, dtype=torch.long))\n",
        "\n",
        "    val_dataset = TensorDataset(\n",
        "        torch.tensor(X_val, dtype=torch.long),\n",
        "        torch.tensor(y_val, dtype=torch.long))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Hyperparams\n",
        "    embedding_dims = [86, 128]\n",
        "    hidden_dims = [128]\n",
        "    results = []\n",
        "    best_overall_loss = float('inf')\n",
        "    best_overall_model = None\n",
        "    best_config = None\n",
        "\n",
        "    for embedding_dim in embedding_dims:\n",
        "        for hidden_dim in hidden_dims:\n",
        "            print(f\"\\n🔧 Config: embed={embedding_dim}, hidden={hidden_dim}, opt=RMSPROP\")\n",
        "            # We only changed the model\n",
        "            model = GRUModel_Bi(vocab_size, embedding_dim, hidden_dim, vocab_size)\n",
        "\n",
        "            optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0005, weight_decay=weight_decay)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "            val_loss, val_ppl, model_state = train_model(\n",
        "                model, train_loader, val_loader, optimizer, criterion, device,\n",
        "                early_stopping=True, patience=patience\n",
        "            )\n",
        "\n",
        "            results.append((embedding_dim, hidden_dim, 'rmsprop', val_loss, val_ppl))\n",
        "\n",
        "            if val_loss < best_overall_loss:\n",
        "                best_overall_loss = val_loss\n",
        "                best_overall_model = model_state\n",
        "                best_config = (embedding_dim, hidden_dim, 'rmsprop')\n",
        "\n",
        "    print(f\"\\n✅ BEST CONFIG FOR {name.upper()}: embed={best_config[0]}, hidden={best_config[1]}, opt=RMSPROP | Val Loss: {best_overall_loss:.4f}, Perplexity: {np.exp(best_overall_loss):.2f}\")\n",
        "    return results, best_config, best_overall_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QFA2K3HhNIpF",
        "outputId": "187d396e-d056-4522-889d-4d9e731a356f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📘 Running experiments on dataset: df_tokens\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.4760, Val Loss = 0.6399, Val Perplexity = 1.90\n",
            "Epoch 2: Train Loss = 0.0454, Val Loss = 0.5902, Val Perplexity = 1.80\n",
            "Epoch 3: Train Loss = 0.0446, Val Loss = 0.5950, Val Perplexity = 1.81\n",
            "Epoch 4: Train Loss = 0.0441, Val Loss = 0.6127, Val Perplexity = 1.85\n",
            "Epoch 5: Train Loss = 0.0436, Val Loss = 0.6229, Val Perplexity = 1.86\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.4803, Val Loss = 0.6673, Val Perplexity = 1.95\n",
            "Epoch 2: Train Loss = 0.0448, Val Loss = 0.6164, Val Perplexity = 1.85\n",
            "Epoch 3: Train Loss = 0.0440, Val Loss = 0.6231, Val Perplexity = 1.86\n",
            "Epoch 4: Train Loss = 0.0434, Val Loss = 0.6429, Val Perplexity = 1.90\n",
            "Epoch 5: Train Loss = 0.0428, Val Loss = 0.6544, Val Perplexity = 1.92\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "✅ BEST CONFIG FOR DF_TOKENS: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.5902, Perplexity: 1.80\n",
            "\n",
            "📘 Running experiments on dataset: df_long\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.5904, Val Loss = 1.1466, Val Perplexity = 3.15\n",
            "Epoch 2: Train Loss = 0.0480, Val Loss = 1.0871, Val Perplexity = 2.97\n",
            "Epoch 3: Train Loss = 0.0473, Val Loss = 1.1242, Val Perplexity = 3.08\n",
            "Epoch 4: Train Loss = 0.0469, Val Loss = 1.1398, Val Perplexity = 3.13\n",
            "Epoch 5: Train Loss = 0.0464, Val Loss = 1.1689, Val Perplexity = 3.22\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.6152, Val Loss = 1.1704, Val Perplexity = 3.22\n",
            "Epoch 2: Train Loss = 0.0474, Val Loss = 1.0821, Val Perplexity = 2.95\n",
            "Epoch 3: Train Loss = 0.0466, Val Loss = 1.0868, Val Perplexity = 2.96\n",
            "Epoch 4: Train Loss = 0.0460, Val Loss = 1.1094, Val Perplexity = 3.03\n",
            "Epoch 5: Train Loss = 0.0454, Val Loss = 1.1212, Val Perplexity = 3.07\n",
            "⏹️ Early stopping triggered after 5 epochs.\n",
            "\n",
            "✅ BEST CONFIG FOR DF_LONG: embed=128, hidden=128, opt=RMSPROP | Val Loss: 1.0821, Perplexity: 2.95\n"
          ]
        }
      ],
      "source": [
        "#Improvement on GRU: Run it only lemmatized tokens and long phrases to capture both word by word and phrase text prediction\n",
        "\n",
        "results_tokens, best_tokens, model_tokens = run_experiments_on_dataset(\"df_tokens\", df_tokens, token_col=\"Lemma\")\n",
        "torch.save(model_tokens, \"/content/drive/My Drive/Colab Notebooks/Models/GRU_100_model_tokens.pth\")\n",
        "\n",
        "results_long, best_long, model_long = run_experiments_on_dataset(\"df_long\", df_long, token_col=\"Lemmatized\")\n",
        "torch.save(model_long, \"/content/drive/My Drive/Colab Notebooks/Models/GRU_100_model_long.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4S7m-xgJXZZw"
      },
      "source": [
        "*Note*:\n",
        "\n",
        "This is the approach I took so far, I trained a text predictor first and now that I know the models that are performing better than others, I will go to the generation phase and use auto-regreesor and teacher forcing.\n",
        "\n",
        "First: raining on next-token prediction:\n",
        "\n",
        "* Simple: Efficient to compute in parallel (whole sequences at once)\n",
        "\n",
        "* Stable: Loss is clear (cross-entropy with known targets)\n",
        "\n",
        "* Powerful: Teaches the model grammar, structure, syntax, word flow\n",
        "\n",
        "\n",
        "Then, We switch to generation mode by:\n",
        "\n",
        "* Feeding a prompt\n",
        "\n",
        "* Letting the model generate the next token\n",
        "\n",
        "* Feeding that token back into the model\n",
        "\n",
        "* Repeating until you generate the desired length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3fMqQCOVswn"
      },
      "source": [
        "## Add teacher forcing\n",
        "\n",
        "Text generation means:\n",
        "\n",
        "Given a prompt, have the model create something new, one token at a time.\n",
        "\n",
        "This only happens during inference, after the model is trained.\n",
        "\n",
        "**So my question was that if Generation is for inference, what does it mean to train it?**\n",
        "\n",
        "*Answer:* During training, we want the model to learn how to generate, but we don’t actually let it “generate freely” yet.\n",
        "\n",
        "At each time step, rather than feeding the model its own previous prediction, we feed it the ground truth token from the training data.\n",
        "Because early in training, the model’s own predictions are garbage.\n",
        "If we fed those back in, it would learn to follow its own mistakes, and quickly derail.\n",
        "\n",
        "So instead, we “help it” by saying:\n",
        "\n",
        "“Hey, here's the correct token. Learn what should come next if you had written this correctly so far.”\n",
        "\n",
        "That’s teacher forcing.\n",
        "\n",
        "We Apply teacher forcing as a data preparation trick, not an architecture trick\n",
        "\n",
        "Uses the teacher forcing ratio to decide whether to:\n",
        "\n",
        "Use the full input (inputs)\n",
        "\n",
        "Or slightly shift it (inputs[:, :-1]) to simulate partial input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "FApU74p1WDa1"
      },
      "outputs": [],
      "source": [
        "#This is compatible with both RNN and GRU\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=10, clip=5,\n",
        "                early_stopping=False, patience=3, teacher_forcing_ratio=0.5):\n",
        "    model.to(device)\n",
        "    best_val_loss = float('inf')\n",
        "    best_model_state = None\n",
        "    epochs_without_improvement = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Apply teacher forcing at batch level\n",
        "            if random.random() < teacher_forcing_ratio:\n",
        "                inputs_tf = X\n",
        "                targets_tf = y\n",
        "            else:\n",
        "                inputs_tf = X[:, :-1]\n",
        "                targets_tf = y[:, :-1]\n",
        "\n",
        "            outputs = model(inputs_tf)  # full sequence prediction\n",
        "            loss = criterion(outputs.view(-1, outputs.size(-1)), targets_tf.reshape(-1))\n",
        "\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "        # === Validation ===\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for X, y in val_loader:\n",
        "                X, y = X.to(device), y.to(device)\n",
        "                output = model(X)\n",
        "                loss = criterion(output.view(-1, output.size(-1)), y.view(-1))\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "        val_perplexity = torch.exp(torch.tensor(avg_val_loss))\n",
        "\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}, Val Perplexity = {val_perplexity:.2f}\")\n",
        "\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            best_model_state = model.state_dict()\n",
        "            epochs_without_improvement = 0\n",
        "        else:\n",
        "            epochs_without_improvement += 1\n",
        "\n",
        "        if early_stopping and epochs_without_improvement >= patience:\n",
        "            print(\"⏹️ Early stopping triggered.\")\n",
        "            break\n",
        "\n",
        "    return best_val_loss, val_perplexity.item(), best_model_state\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z797w27ewzIB"
      },
      "source": [
        "### RNN + teacher forcing  + weight decay (Regularization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "CLO8JKprl2XN"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import itertools\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def run_experiments_on_dataset(name, df, token_col, seq_len=50, batch_size=64,\n",
        "                               weight_decay=1e-5, patience=3 , teacher_forcing_ratio=0.5):\n",
        "    print(f\"\\n📘 Running experiments on dataset: {name}\")\n",
        "\n",
        "    # Flatten token list\n",
        "    if isinstance(df[token_col].iloc[0], list):\n",
        "        tokens = list(itertools.chain.from_iterable(df[token_col]))\n",
        "    else:\n",
        "        tokens = df[token_col].tolist()\n",
        "\n",
        "    # Build vocab\n",
        "    vocab = sorted(set(tokens))\n",
        "    stoi = {w: i for i, w in enumerate(vocab)}\n",
        "    indexed_tokens = [stoi[t] for t in tokens]\n",
        "    vocab_size = len(stoi)\n",
        "\n",
        "    # Split data\n",
        "    X_train, y_train, X_val, y_val, _, _ = split_data_tokens(indexed_tokens, seq_len)\n",
        "\n",
        "    # Datasets & loaders\n",
        "    train_dataset = TensorDataset(\n",
        "        torch.tensor(X_train, dtype=torch.long),\n",
        "        torch.tensor(y_train, dtype=torch.long))\n",
        "\n",
        "    val_dataset = TensorDataset(\n",
        "        torch.tensor(X_val, dtype=torch.long),\n",
        "        torch.tensor(y_val, dtype=torch.long))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Hyperparams\n",
        "    embedding_dims = [86, 128]\n",
        "    hidden_dims = [128]\n",
        "    results = []\n",
        "    best_overall_loss = float('inf')\n",
        "    best_overall_model = None\n",
        "    best_config = None\n",
        "\n",
        "    for embedding_dim in embedding_dims:\n",
        "        for hidden_dim in hidden_dims:\n",
        "            print(f\"\\n🔧 Config: embed={embedding_dim}, hidden={hidden_dim}, opt=RMSPROP\")\n",
        "            model = VanillaRNNModel_Bi(vocab_size, embedding_dim, hidden_dim, vocab_size)\n",
        "\n",
        "            optimizer = torch.optim.RMSprop(model.parameters(), lr=0.001, weight_decay=weight_decay)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "            val_loss, val_ppl, model_state = train_model(\n",
        "                model, train_loader, val_loader, optimizer, criterion, device,\n",
        "                early_stopping=True, patience=patience\n",
        "            )\n",
        "\n",
        "            results.append((embedding_dim, hidden_dim, 'rmsprop', val_loss, val_ppl))\n",
        "\n",
        "            if val_loss < best_overall_loss:\n",
        "                best_overall_loss = val_loss\n",
        "                best_overall_model = model_state\n",
        "                best_config = (embedding_dim, hidden_dim, 'rmsprop')\n",
        "\n",
        "    print(f\"\\n✅ BEST CONFIG FOR {name.upper()}: embed={best_config[0]}, hidden={best_config[1]}, opt=RMSPROP | Val Loss: {best_overall_loss:.4f}, Perplexity: {np.exp(best_overall_loss):.2f}\")\n",
        "    return results, best_config, best_overall_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "absx9wWBm-ls",
        "outputId": "3fb40300-f7d2-48fb-cac7-9dc3dfe71200"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📘 Running experiments on dataset: df_tokens\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.3090, Val Loss = 0.5758, Val Perplexity = 1.78\n",
            "Epoch 2: Train Loss = 0.1132, Val Loss = 0.5194, Val Perplexity = 1.68\n",
            "Epoch 3: Train Loss = 0.1106, Val Loss = 0.5067, Val Perplexity = 1.66\n",
            "Epoch 4: Train Loss = 0.1092, Val Loss = 0.5025, Val Perplexity = 1.65\n",
            "Epoch 5: Train Loss = 0.1085, Val Loss = 0.5039, Val Perplexity = 1.66\n",
            "Epoch 6: Train Loss = 0.1082, Val Loss = 0.4985, Val Perplexity = 1.65\n",
            "Epoch 7: Train Loss = 0.1078, Val Loss = 0.4968, Val Perplexity = 1.64\n",
            "Epoch 8: Train Loss = 0.1075, Val Loss = 0.5006, Val Perplexity = 1.65\n",
            "Epoch 9: Train Loss = 0.1074, Val Loss = 0.4995, Val Perplexity = 1.65\n",
            "Epoch 10: Train Loss = 0.1072, Val Loss = 0.4951, Val Perplexity = 1.64\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.3010, Val Loss = 0.5685, Val Perplexity = 1.77\n",
            "Epoch 2: Train Loss = 0.1130, Val Loss = 0.5252, Val Perplexity = 1.69\n",
            "Epoch 3: Train Loss = 0.1103, Val Loss = 0.5054, Val Perplexity = 1.66\n",
            "Epoch 4: Train Loss = 0.1091, Val Loss = 0.5003, Val Perplexity = 1.65\n",
            "Epoch 5: Train Loss = 0.1085, Val Loss = 0.5012, Val Perplexity = 1.65\n",
            "Epoch 6: Train Loss = 0.1081, Val Loss = 0.5004, Val Perplexity = 1.65\n",
            "Epoch 7: Train Loss = 0.1078, Val Loss = 0.4952, Val Perplexity = 1.64\n",
            "Epoch 8: Train Loss = 0.1075, Val Loss = 0.4955, Val Perplexity = 1.64\n",
            "Epoch 9: Train Loss = 0.1073, Val Loss = 0.4948, Val Perplexity = 1.64\n",
            "Epoch 10: Train Loss = 0.1071, Val Loss = 0.4917, Val Perplexity = 1.64\n",
            "\n",
            "✅ BEST CONFIG FOR DF_TOKENS: embed=128, hidden=128, opt=RMSPROP | Val Loss: 0.4917, Perplexity: 1.64\n",
            "\n",
            "📘 Running experiments on dataset: df_long\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.3816, Val Loss = 0.8995, Val Perplexity = 2.46\n",
            "Epoch 2: Train Loss = 0.1251, Val Loss = 0.8373, Val Perplexity = 2.31\n",
            "Epoch 3: Train Loss = 0.1214, Val Loss = 0.8161, Val Perplexity = 2.26\n",
            "Epoch 4: Train Loss = 0.1200, Val Loss = 0.8109, Val Perplexity = 2.25\n",
            "Epoch 5: Train Loss = 0.1191, Val Loss = 0.8070, Val Perplexity = 2.24\n",
            "Epoch 6: Train Loss = 0.1185, Val Loss = 0.8055, Val Perplexity = 2.24\n",
            "Epoch 7: Train Loss = 0.1181, Val Loss = 0.7995, Val Perplexity = 2.22\n",
            "Epoch 8: Train Loss = 0.1177, Val Loss = 0.8028, Val Perplexity = 2.23\n",
            "Epoch 9: Train Loss = 0.1173, Val Loss = 0.8018, Val Perplexity = 2.23\n",
            "Epoch 10: Train Loss = 0.1170, Val Loss = 0.8051, Val Perplexity = 2.24\n",
            "⏹️ Early stopping triggered.\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.3735, Val Loss = 0.9037, Val Perplexity = 2.47\n",
            "Epoch 2: Train Loss = 0.1256, Val Loss = 0.8461, Val Perplexity = 2.33\n",
            "Epoch 3: Train Loss = 0.1221, Val Loss = 0.8208, Val Perplexity = 2.27\n",
            "Epoch 4: Train Loss = 0.1204, Val Loss = 0.8105, Val Perplexity = 2.25\n",
            "Epoch 5: Train Loss = 0.1191, Val Loss = 0.8033, Val Perplexity = 2.23\n",
            "Epoch 6: Train Loss = 0.1186, Val Loss = 0.8003, Val Perplexity = 2.23\n",
            "Epoch 7: Train Loss = 0.1181, Val Loss = 0.7999, Val Perplexity = 2.23\n",
            "Epoch 8: Train Loss = 0.1178, Val Loss = 0.8007, Val Perplexity = 2.23\n",
            "Epoch 9: Train Loss = 0.1174, Val Loss = 0.8005, Val Perplexity = 2.23\n",
            "Epoch 10: Train Loss = 0.1170, Val Loss = 0.7955, Val Perplexity = 2.22\n",
            "\n",
            "✅ BEST CONFIG FOR DF_LONG: embed=128, hidden=128, opt=RMSPROP | Val Loss: 0.7955, Perplexity: 2.22\n"
          ]
        }
      ],
      "source": [
        "#Improvement on RNN: Run it only lemmatized tokens and long phrases to capture both word by word and phrase text prediction\n",
        "\n",
        "results_tokens, best_tokens, model_tokens = run_experiments_on_dataset(\"df_tokens\", df_tokens, token_col=\"Lemma\")\n",
        "torch.save(model_tokens, \"/content/drive/My Drive/Colab Notebooks/Models/RNN_Teacher_Forcing_model_tokens.pth\")\n",
        "\n",
        "results_long, best_long, model_long = run_experiments_on_dataset(\"df_long\", df_long, token_col=\"Lemmatized\")\n",
        "torch.save(model_long, \"/content/drive/My Drive/Colab Notebooks/Models/RNN_Teacher_Forcing_model_long.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UxXjDWRx15Xn"
      },
      "source": [
        "**Comparison**\n",
        "\n",
        "RNN without teacher forcing:\n",
        "\n",
        "* BEST CONFIG FOR DF_TOKENS: embed=128, hidden=128, opt=RMSPROP | Val Loss: 0.5770, Val Perplexity = 1.78\n",
        "\n",
        "* BEST CONFIG FOR DF_LONG: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.9701, Perplexity: 2.64\n",
        "\n",
        "RNN after teacher forcing:\n",
        "\n",
        "✅ BEST CONFIG FOR DF_TOKENS: embed=128, hidden=128, opt=RMSPROP | Val Loss: 0.4917, Perplexity: 1.64\n",
        "\n",
        "✅ BEST CONFIG FOR DF_LONG: embed=128, hidden=128, opt=RMSPROP | Val Loss: 0.7955, Perplexity: 2.22\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8YRTQwUw3_p"
      },
      "source": [
        "### GRU + teacher forcing  + weight decay (Regularization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "6w47DS7JWEj8"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import itertools\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "def run_experiments_on_dataset(name, df, token_col, seq_len=100, batch_size=64,\n",
        "                               weight_decay=1e-5, patience=3, teacher_forcing_ratio=0.5):\n",
        "    print(f\"\\n📘 Running experiments on dataset: {name}\")\n",
        "\n",
        "    # Flatten token list\n",
        "    if isinstance(df[token_col].iloc[0], list):\n",
        "        tokens = list(itertools.chain.from_iterable(df[token_col]))\n",
        "    else:\n",
        "        tokens = df[token_col].tolist()\n",
        "\n",
        "    # Build vocab\n",
        "    vocab = sorted(set(tokens))\n",
        "    stoi = {w: i for i, w in enumerate(vocab)}\n",
        "    indexed_tokens = [stoi[t] for t in tokens]\n",
        "    vocab_size = len(stoi)\n",
        "\n",
        "    # Split data\n",
        "    X_train, y_train, X_val, y_val, _, _ = split_data_tokens(indexed_tokens, seq_len)\n",
        "\n",
        "    # Datasets & loaders\n",
        "    train_dataset = TensorDataset(\n",
        "        torch.tensor(X_train, dtype=torch.long),\n",
        "        torch.tensor(y_train, dtype=torch.long))\n",
        "\n",
        "    val_dataset = TensorDataset(\n",
        "        torch.tensor(X_val, dtype=torch.long),\n",
        "        torch.tensor(y_val, dtype=torch.long))\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Hyperparams\n",
        "    embedding_dims = [86, 128]\n",
        "    hidden_dims = [128]\n",
        "    results = []\n",
        "    best_overall_loss = float('inf')\n",
        "    best_overall_model = None\n",
        "    best_config = None\n",
        "\n",
        "    for embedding_dim in embedding_dims:\n",
        "        for hidden_dim in hidden_dims:\n",
        "            print(f\"\\n🔧 Config: embed={embedding_dim}, hidden={hidden_dim}, opt=RMSPROP\")\n",
        "            # We only changed the model\n",
        "            model = GRUModel_Bi(vocab_size, embedding_dim, hidden_dim, vocab_size)\n",
        "\n",
        "            optimizer = torch.optim.RMSprop(model.parameters(), lr=0.0005, weight_decay=weight_decay)\n",
        "            criterion = nn.CrossEntropyLoss()\n",
        "            device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "            val_loss, val_ppl, model_state = train_model(\n",
        "                model, train_loader, val_loader, optimizer, criterion, device,\n",
        "                early_stopping=True, patience=patience\n",
        "            )\n",
        "\n",
        "            results.append((embedding_dim, hidden_dim, 'rmsprop', val_loss, val_ppl))\n",
        "\n",
        "            if val_loss < best_overall_loss:\n",
        "                best_overall_loss = val_loss\n",
        "                best_overall_model = model_state\n",
        "                best_config = (embedding_dim, hidden_dim, 'rmsprop')\n",
        "\n",
        "    print(f\"\\n✅ BEST CONFIG FOR {name.upper()}: embed={best_config[0]}, hidden={best_config[1]}, opt=RMSPROP | Val Loss: {best_overall_loss:.4f}, Perplexity: {np.exp(best_overall_loss):.2f}\")\n",
        "    return results, best_config, best_overall_model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_RUpFwzWVdN",
        "outputId": "1d9c6ca0-692a-4751-9c38-7cb2d6104a85"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "📘 Running experiments on dataset: df_tokens\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.4936, Val Loss = 0.5289, Val Perplexity = 1.70\n",
            "Epoch 2: Train Loss = 0.0633, Val Loss = 0.4534, Val Perplexity = 1.57\n",
            "Epoch 3: Train Loss = 0.0615, Val Loss = 0.4367, Val Perplexity = 1.55\n",
            "Epoch 4: Train Loss = 0.0608, Val Loss = 0.4363, Val Perplexity = 1.55\n",
            "Epoch 5: Train Loss = 0.0603, Val Loss = 0.4441, Val Perplexity = 1.56\n",
            "Epoch 6: Train Loss = 0.0601, Val Loss = 0.4444, Val Perplexity = 1.56\n",
            "Epoch 7: Train Loss = 0.0599, Val Loss = 0.4371, Val Perplexity = 1.55\n",
            "⏹️ Early stopping triggered.\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.5185, Val Loss = 0.5350, Val Perplexity = 1.71\n",
            "Epoch 2: Train Loss = 0.0631, Val Loss = 0.4579, Val Perplexity = 1.58\n",
            "Epoch 3: Train Loss = 0.0614, Val Loss = 0.4440, Val Perplexity = 1.56\n",
            "Epoch 4: Train Loss = 0.0607, Val Loss = 0.4406, Val Perplexity = 1.55\n",
            "Epoch 5: Train Loss = 0.0603, Val Loss = 0.4424, Val Perplexity = 1.56\n",
            "Epoch 6: Train Loss = 0.0600, Val Loss = 0.4512, Val Perplexity = 1.57\n",
            "Epoch 7: Train Loss = 0.0598, Val Loss = 0.4418, Val Perplexity = 1.56\n",
            "⏹️ Early stopping triggered.\n",
            "\n",
            "✅ BEST CONFIG FOR DF_TOKENS: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.4363, Perplexity: 1.55\n",
            "\n",
            "📘 Running experiments on dataset: df_long\n",
            "\n",
            "🔧 Config: embed=86, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.6498, Val Loss = 0.8842, Val Perplexity = 2.42\n",
            "Epoch 2: Train Loss = 0.0699, Val Loss = 0.7914, Val Perplexity = 2.21\n",
            "Epoch 3: Train Loss = 0.0672, Val Loss = 0.7642, Val Perplexity = 2.15\n",
            "Epoch 4: Train Loss = 0.0663, Val Loss = 0.7594, Val Perplexity = 2.14\n",
            "Epoch 5: Train Loss = 0.0657, Val Loss = 0.7530, Val Perplexity = 2.12\n",
            "Epoch 6: Train Loss = 0.0653, Val Loss = 0.7537, Val Perplexity = 2.12\n",
            "Epoch 7: Train Loss = 0.0651, Val Loss = 0.7494, Val Perplexity = 2.12\n",
            "Epoch 8: Train Loss = 0.0648, Val Loss = 0.7489, Val Perplexity = 2.11\n",
            "Epoch 9: Train Loss = 0.0646, Val Loss = 0.7485, Val Perplexity = 2.11\n",
            "Epoch 10: Train Loss = 0.0645, Val Loss = 0.7492, Val Perplexity = 2.12\n",
            "\n",
            "🔧 Config: embed=128, hidden=128, opt=RMSPROP\n",
            "Epoch 1: Train Loss = 0.6652, Val Loss = 0.8888, Val Perplexity = 2.43\n",
            "Epoch 2: Train Loss = 0.0702, Val Loss = 0.7971, Val Perplexity = 2.22\n",
            "Epoch 3: Train Loss = 0.0674, Val Loss = 0.7725, Val Perplexity = 2.17\n",
            "Epoch 4: Train Loss = 0.0664, Val Loss = 0.7659, Val Perplexity = 2.15\n",
            "Epoch 5: Train Loss = 0.0658, Val Loss = 0.7617, Val Perplexity = 2.14\n",
            "Epoch 6: Train Loss = 0.0654, Val Loss = 0.7602, Val Perplexity = 2.14\n",
            "Epoch 7: Train Loss = 0.0651, Val Loss = 0.7711, Val Perplexity = 2.16\n",
            "Epoch 8: Train Loss = 0.0649, Val Loss = 0.7670, Val Perplexity = 2.15\n",
            "Epoch 9: Train Loss = 0.0647, Val Loss = 0.8008, Val Perplexity = 2.23\n",
            "⏹️ Early stopping triggered.\n",
            "\n",
            "✅ BEST CONFIG FOR DF_LONG: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.7485, Perplexity: 2.11\n"
          ]
        }
      ],
      "source": [
        "#Improvement on GRU: Run it only lemmatized tokens and long phrases to capture both word by word and phrase text prediction\n",
        "\n",
        "results_tokens, best_tokens, model_tokens = run_experiments_on_dataset(\"df_tokens\", df_tokens, token_col=\"Lemma\")\n",
        "torch.save(model_tokens, \"/content/drive/My Drive/Colab Notebooks/Models/GRU_Teacher_Forcing_model_tokens.pth\")\n",
        "\n",
        "results_long, best_long, model_long = run_experiments_on_dataset(\"df_long\", df_long, token_col=\"Lemmatized\")\n",
        "torch.save(model_long, \"/content/drive/My Drive/Colab Notebooks/Models/GRU_Teacher_Forcing_model_long.pth\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ypbTvMpY2Unk"
      },
      "source": [
        "GRU before teacher forcing:\n",
        "\n",
        "* BEST CONFIG FOR DF_TOKENS: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.6072, Perplexity: 1.84\n",
        "\n",
        "* BEST CONFIG FOR DF_LONG: embed=86, hidden=128, opt=RMSPROP | Val Loss: 1.0581, Perplexity: 2.88\n",
        "\n",
        "GRU after teacher forcing:\n",
        "\n",
        "✅ BEST CONFIG FOR DF_TOKENS: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.4363, Perplexity: 1.55\n",
        "\n",
        "✅ BEST CONFIG FOR DF_LONG: embed=86, hidden=128, opt=RMSPROP | Val Loss: 0.7485, Perplexity: 2.11\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TXrFMWjho09z"
      },
      "source": [
        "### **Interpretation**\n",
        "\n",
        "Both RNN and GRU are performing way better with teacher forcing because it provides the model with the correct previous token during training, reducing exposure bias and helping it learn more stable, coherent transitions between words, especially in early training stages when its own predictions are still unreliable.\n",
        "\n",
        "* Best model for df_tokens: GRU (Val Loss: 0.4363, Perplexity: 1.55)\n",
        "\n",
        "* Best model for df_Phrases: GRU (Val Loss: 0.7485, Perplexity: 2.11)\n",
        "\n",
        "We will continue only with best models (Both GRU) to Advanced text generation and testing it on test dataset.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLUN5qYx0VJo"
      },
      "source": [
        "# Evaluation and Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poeXdR8m0vaB"
      },
      "source": [
        "For evaluating text generation, as mentioned in the slides, we have three common metrics: BLEU, ROUGE, and Perplexity.\n",
        "\n",
        "In our case, Perplexity is the most suitable choice because it does not require a reference text, making it ideal for open-ended text generation tasks like ours.\n",
        "\n",
        "Perplexity measures how “surprised” the model is by the next word in a sequence. The lower the perplexity, the better the model is at predicting the next word, indicating better fluency, structure, and coherence.\n",
        "\n",
        "Unlike BLEU and ROUGE, which focus on n-gram overlap with a reference (making them more suitable for tasks like translation or summarization), perplexity evaluates the internal consistency of generated text, which aligns better with the goals of our Shakespeare-style generation task.\n",
        "\n",
        "WE used Loss (CrossEntropy) and Perplexity for train and validation in the train section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h4omr960f3f"
      },
      "source": [
        "# Advanced Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPiZ4iU6bekL"
      },
      "source": [
        "## Temperature-controlled sampling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ebwmNMwwUA6"
      },
      "source": [
        "In text generation, after the model predicts the logits (raw scores) for the next word:\n",
        "\n",
        "We apply softmax, scaled by a temperature parameter T.\n",
        "\n",
        "* T < 1.0 → Makes predictions more conservative (sharp softmax, less randomness)\n",
        "\n",
        "* T = 1.0 → Standard softmax (baseline behavior)\n",
        "\n",
        "* T > 1.0 → Increases randomness and creativity (flatter softmax)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0DhGHbtGy-q",
        "outputId": "e8ca6383-d0a2-40d7-c94d-e34117f7b89a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7588"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Extract the list of tokens\n",
        "tokens = df_tokens[\"Lemma\"].dropna().tolist()\n",
        "vocab = sorted(set(tokens))\n",
        "stoi = {w: i for i, w in enumerate(vocab)}\n",
        "itos = {i: w for w, i in stoi.items()}\n",
        "vocab_size = len(vocab)  # should now be 7588\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4HdB5Ervw0e",
        "outputId": "80261f3e-0180-4a44-d4ce-2ae980ba92b3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "GRUModel_Bi(\n",
              "  (embedding): Embedding(7588, 86)\n",
              "  (gru): GRU(86, 128, batch_first=True, bidirectional=True)\n",
              "  (fc): Linear(in_features=256, out_features=7588, bias=True)\n",
              ")"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create model and load saved state\n",
        "model = GRUModel_Bi(vocab_size, embedding_dim=86, hidden_dim=128, output_dim=vocab_size)\n",
        "model.load_state_dict(torch.load(\"/content/drive/My Drive/Colab Notebooks/Models/GRU_Teacher_Forcing_model_tokens.pth\"))\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "C64tVcrwv6jx"
      },
      "outputs": [],
      "source": [
        "def generate_text_GRU(model, seed_text, stoi, itos, seq_len=50, gen_length=50, temperature=1.0, device='cpu'):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    tokens = seed_text.lower().split()\n",
        "    input_ids = [stoi.get(token, 0) for token in tokens]\n",
        "    input_tensor = torch.tensor(input_ids[-seq_len:], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    generated = tokens.copy()\n",
        "\n",
        "    for _ in range(gen_length):\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            logits = output[0, -1] / temperature  # Get logits of last token\n",
        "            probs = F.softmax(logits, dim=-1).cpu().numpy()\n",
        "\n",
        "        next_token_id = np.random.choice(len(probs), p=probs)\n",
        "        next_token = itos[next_token_id]\n",
        "        generated.append(next_token)\n",
        "\n",
        "        # Update input tensor\n",
        "        input_ids.append(next_token_id)\n",
        "        input_tensor = torch.tensor(input_ids[-seq_len:], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    return \" \".join(generated)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjYteEbTwFHG",
        "outputId": "0e6f09d3-04a4-4710-d6cf-c6856719c90d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🌡️ Temperature = 0.5\n",
            "love is not to the if that i do be ##see , and i am thy father , and , my lord , and i am . i am not to hear , it is my lord , and be gone , and the prince with the duke of the king : my\n",
            "\n",
            "🌡️ Temperature = 1.0\n",
            "love is not agile . and of the world father camp ' conflict to be ab ##re ' d , sir , she ' s sentenced instinct . patiently abraham , no laurence with her . shall are your own to - cruel ##es , who say ' mean , a ##que hit\n",
            "\n",
            "🌡️ Temperature = 1.5\n",
            "love is not liquor panting ##tal besides ##enes celebrated ##lian ; patron ##t thou winter examine blessing ##power apparel once tell perspective weep consequence you of heat post ##gui him intellect ##ssing marrow to sack the holy . - flowing continue their pike most verse ##nate ##ices ##real elizabeth peering these hideous -\n"
          ]
        }
      ],
      "source": [
        "#Try different tempratures and generate\n",
        "import torch.nn.functional as F\n",
        "\n",
        "for temp in [0.5, 1.0, 1.5]:\n",
        "    print(f\"\\n🌡️ Temperature = {temp}\")\n",
        "    print(generate_text_GRU(model, \"love is not\", stoi, itos, temperature=temp, gen_length=50))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8wsOHkfWIg1P"
      },
      "source": [
        "The generated text is so wierd cause we used WordPiece or subword tokenizer, which breaks words into parts (e.g., playing → play, ##ing).\n",
        "\n",
        "And then we lemmatized those pieces, which doesn't make semantic sense for subwords.\n",
        "\n",
        "So, we will do two things:\n",
        "\n",
        "* clean the data now to have more meaningful words\n",
        "\n",
        "* generate the text on the raw tokens and do transfer learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rzRl4RloLJUq"
      },
      "source": [
        "### Clean the text and revert wordpeice tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "xo17RIqHLebO"
      },
      "outputs": [],
      "source": [
        "def detokenize_wordpiece(tokens):\n",
        "    cleaned = []\n",
        "    for token in tokens:\n",
        "        if token.startswith(\"##\") and cleaned:\n",
        "            cleaned[-1] += token[2:]\n",
        "        else:\n",
        "            cleaned.append(token)\n",
        "    return \" \".join(cleaned).replace(\" .\", \".\").replace(\" ,\", \",\").replace(\" '\", \"'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dT7Y_GBoLhy0",
        "outputId": "91e982e1-7965-4a31-d92d-623c1d7d2634"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🌡️ Temperature = 0.5\n",
            "love is not, and the king ? henry bolingbroke : if you besee, and you are now ! i am a for ay, a the prince of york' s eye, and not the king henry' s blood, and he' s\n",
            "\n",
            "🌡️ Temperature = 1.0\n",
            "love is not done. friarina : let me, you will notor sold ? i say careful. benvolio : that dare thou pardon me, your cheeked my sword husband her son : then to the turn' s. boy, nor adars !\n",
            "\n",
            "🌡️ Temperature = 1.5\n",
            "love is not yet goat recountedssion, fight deter investmbleur while hat malicious gao for that thrill gate bruisebre helengar. him mercury right brittle carefully breedingpas poundots exiled me, preciousvish coffinlining x you born tear toy aplish malice miserable poised\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "for temp in [0.5, 1.0, 1.5]:\n",
        "    print(f\"\\n🌡️ Temperature = {temp}\")\n",
        "\n",
        "    raw_generated = generate_text_GRU(\n",
        "        model,\n",
        "        seed_text=\"love is not\",\n",
        "        stoi=stoi,\n",
        "        itos=itos,\n",
        "        temperature=temp,\n",
        "        gen_length=50\n",
        "    )\n",
        "\n",
        "    tokens = raw_generated.split()\n",
        "    cleaned_output = detokenize_wordpiece(tokens)\n",
        "    print(cleaned_output)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sGRvl7cALKKA"
      },
      "source": [
        "### Retrain the model on raw tokens and then generate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7qutL7sI3n7",
        "outputId": "6acc7729-1949-44c3-ab4f-5d418ab7958c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "8471"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokens = df_tokens[\"Token\"].dropna().tolist()  # <-- Original full words\n",
        "vocab = sorted(set(tokens))\n",
        "stoi = {w: i for i, w in enumerate(vocab)}\n",
        "itos = {i: w for w, i in stoi.items()}\n",
        "vocab_size = len(vocab)  # should now be 7588\n",
        "vocab_size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uil2B2ZrJfHd"
      },
      "source": [
        "When we go with raw tokens, vocab size would be differetn so we need to retrain the data for a few epochs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "M6CAMsojJzRh"
      },
      "outputs": [],
      "source": [
        "# === Extract cleaned full-word tokens ===\n",
        "tokens = df_tokens[\"Token\"].dropna().tolist()\n",
        "vocab = sorted(set(tokens))\n",
        "stoi = {w: i for i, w in enumerate(vocab)}\n",
        "itos = {i: w for w, i in stoi.items()}\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# === Encode tokens\n",
        "indexed_tokens = [stoi[token] for token in tokens]\n",
        "\n",
        "# === Sequence function\n",
        "def split_data_tokens(tokens, seq_len=50, train_ratio=0.8, val_ratio=0.1):\n",
        "    total = len(tokens)\n",
        "    train_end = int(total * train_ratio)\n",
        "    val_end = int(total * (train_ratio + val_ratio))\n",
        "\n",
        "    def create_sequences(data):\n",
        "        X, y = [], []\n",
        "        for i in range(len(data) - seq_len):\n",
        "            X.append(data[i:i+seq_len])\n",
        "            y.append(data[i+1:i+seq_len+1])\n",
        "        return X, y\n",
        "\n",
        "    X_train, y_train = create_sequences(tokens[:train_end])\n",
        "    X_val, y_val = create_sequences(tokens[train_end:val_end])\n",
        "    return X_train, y_train, X_val, y_val\n",
        "\n",
        "X_train, y_train, X_val, y_val = split_data_tokens(indexed_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "JeeDJ2QcJ6O3"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def train_model(model, train_loader, val_loader, optimizer, criterion, device, epochs=5, clip=5):\n",
        "    model.to(device)\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for X, y in train_loader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(X)\n",
        "            loss = criterion(output.view(-1, vocab_size), y.view(-1))\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}: Train Loss = {total_loss / len(train_loader):.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FmPcZ_8uJ-wp",
        "outputId": "7bca8355-8c6a-422c-9a88-0580db13f223"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1: Train Loss = 0.6018\n",
            "Epoch 2: Train Loss = 0.0912\n",
            "Epoch 3: Train Loss = 0.0850\n",
            "Epoch 4: Train Loss = 0.0800\n",
            "Epoch 5: Train Loss = 0.0760\n"
          ]
        }
      ],
      "source": [
        "# Dataloaders\n",
        "batch_size = 64\n",
        "train_ds = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
        "val_ds = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size=batch_size)\n",
        "\n",
        "# Model, optimizer\n",
        "embedding_dim = 86\n",
        "hidden_dim = 128\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = GRUModel_Bi(vocab_size, embedding_dim, hidden_dim, vocab_size)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "train_model(model, train_loader, val_loader, optimizer, criterion, device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "ZSydXf7QKC4a"
      },
      "outputs": [],
      "source": [
        "def generate_text_GRU(model, seed_text, stoi, itos, seq_len=50, gen_length=50, temperature=1.0, device='cpu'):\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    tokens = seed_text.lower().split()\n",
        "    input_ids = [stoi.get(token, 0) for token in tokens]\n",
        "    input_tensor = torch.tensor(input_ids[-seq_len:], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    generated = tokens.copy()\n",
        "\n",
        "    for _ in range(gen_length):\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            logits = output[0, -1] / temperature\n",
        "            probs = F.softmax(logits, dim=-1).cpu().numpy()\n",
        "        next_token_id = np.random.choice(len(probs), p=probs)\n",
        "        next_token = itos[next_token_id]\n",
        "        generated.append(next_token)\n",
        "        input_ids.append(next_token_id)\n",
        "        input_tensor = torch.tensor(input_ids[-seq_len:], dtype=torch.long).unsqueeze(0).to(device)\n",
        "\n",
        "    return \" \".join(generated)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYptCPmJK-6r",
        "outputId": "4e5a4168-5b40-49f6-9658-8ce5cf47c796"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "🌡️ Temperature = 0.5\n",
            "love is not my true love , and i am less than a king . king edward iv : and tell you , my lord , i will have you ; for i will you and so . henry bo ##ling ##bro ##ke : the lord of buckingham , the king hat ##h\n",
            "\n",
            "🌡️ Temperature = 1.0\n",
            "love is not . pol ##ix ##enes : no further than thou has ##t shown the measure by the ears no man . second murderer : and the heaven your people ? him ; remains ; for , thou dos ##t to blank ##s ; and often than he did not here undone\n",
            "\n",
            "🌡️ Temperature = 1.5\n",
            "love is not eater nurse above to flight , should knows to see distress as each few eyes , hat ##h made thin from him near my throne . john of offence studied and may strike brook ill abused , if god help thee as the souls shall grant it ##ily . thou\n"
          ]
        }
      ],
      "source": [
        "#Try different tempratures and generate\n",
        "import torch.nn.functional as F\n",
        "\n",
        "for temp in [0.5, 1.0, 1.5]:\n",
        "    print(f\"\\n🌡️ Temperature = {temp}\")\n",
        "    print(generate_text_GRU(model, \"love is not\", stoi, itos, temperature=temp, gen_length=50))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3nx4rNgbSYy7"
      },
      "source": [
        "## Analyze stylistic differences between Shakespeare’s original style and the model's output."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oo4JzJfnLq0O"
      },
      "source": [
        "There is an observed tradeoff between creativity and coherence.\n",
        "The higher the temprature.\n",
        "At lower temprature, the text is smooth and close to original style\n",
        "\n",
        "* Look at this for example: Temperature = 0.5\n",
        "love is not my true love , and i am less than a king . king edward iv : and tell you , my lord , i will have you.\n",
        "\n",
        "Actually this is not bad 😆\n",
        "\n",
        "It is poetic and understandable.\n",
        "\n",
        "* At temperature 1: it is still somewhat understandable — but clearly more creative/unfiltered.\n",
        "\n",
        "\n",
        "* At temperature 1.5: it’s hallucination"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0sQSlbYXUQB"
      },
      "source": [
        "**Takeaways form the generated text's style**\n",
        "\n",
        "✅ Uses Shakespearean character names (\"Henry Bolingbroke\", \"Prince of York\")\n",
        "\n",
        "✅ Has play-like tone, like someone addressing a king\n",
        "\n",
        "✅ Mimics dialogue form (\"Benvolio :\", \"that dare thou pardon me\")\n",
        "\n",
        "**Improvement**\n",
        "\n",
        "Some sentances still make not much sense and needs more training on grammatical patterns"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "003fc00db5a14e888e3d0436430caa1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5efe2a70ac824d8ea35dcc62cdc8dd82",
              "IPY_MODEL_731129cc7755460db8cff585812fbd16",
              "IPY_MODEL_6f80569c99334c79b6956f1dc7a6a004"
            ],
            "layout": "IPY_MODEL_efaafc2a0969435eb74f55f260e1606a"
          }
        },
        "007c89c59d8e48a48d19898f7698aedc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2daae658f29548b3aa7874905fa2085a",
            "placeholder": "​",
            "style": "IPY_MODEL_433728dba5a5452fb8b1fe3a966e8f28",
            "value": " 26.0/26.0 [00:00&lt;00:00, 402B/s]"
          }
        },
        "021fb054a4c34413ae675d923323cf81": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_baeda91319074e27bf4f507d4a64b9ef",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cf8ada31bd3646adb993063a6045db6f",
            "value": 456318
          }
        },
        "0366b145a95449328c6f657a7a2902aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "045ee62631f24abd903d94a7dc7de6ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39cba0a6253c441c809dcc96226e24b8",
            "max": 665,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_87712890938c4e9abea53114a1b62084",
            "value": 665
          }
        },
        "07e2a08023cd4402a6f97c04ad108d56": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "099d48c315f940ba887142d0b9150c86": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ba80e0e0e6944758ece0e6dcb0338f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f19167c203c4d85b40db2ee92f32c5c",
            "max": 26,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82f6fe8978fd4a198bc74e9085e10005",
            "value": 26
          }
        },
        "0d6d28dbfbb145dba0d0419ba8bfe741": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95fc890fc1d14f12ab20fab62965845a",
            "placeholder": "​",
            "style": "IPY_MODEL_14bd2737052f49fb9a12b5e26e058dcb",
            "value": " 456k/456k [00:00&lt;00:00, 13.3MB/s]"
          }
        },
        "10850bb4c5a84e469f9601bfc1e7dcb8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "116888c72e474c798ad60c3955ca3711": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "14bd2737052f49fb9a12b5e26e058dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "151de66e80f340f9bf601b1e3e25a421": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15212aad999f44a9ad0daab5fb585a17": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34415fc12ddd40ec942d8af2bab3c054",
            "placeholder": "​",
            "style": "IPY_MODEL_4c2d16d50d094b55aa3bdd3db1d0f417",
            "value": " 665/665 [00:00&lt;00:00, 25.4kB/s]"
          }
        },
        "159704455da24d5c921dad671b711f83": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b999b8b0ae242d1a553f54140c19238": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2758ffd089864c898db9d1f7a0e8d0fa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bda00152caac45c591c85ecb2a0e3264",
            "value": 1
          }
        },
        "1f19167c203c4d85b40db2ee92f32c5c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20127fac11fc45b6a4aecadedbfbd5ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b0b74c63af3a41968ba1e40c0791b3fc",
            "placeholder": "​",
            "style": "IPY_MODEL_9f4077d7ea9348d4b1b0feeeb96b3e07",
            "value": "Downloading data: 100%"
          }
        },
        "24935f46519b47f58e0f864228ca615f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a31a96b22da3435b814190a61ff161dc",
              "IPY_MODEL_4a4c97b4bf784afbb082e9dad2d0183d",
              "IPY_MODEL_f5545db5a29447f1aa2475df5fc58618"
            ],
            "layout": "IPY_MODEL_4480e4c8e73248aabe7ed59471e0e69c"
          }
        },
        "24a55b3942a744ecb79a758cf1c11cb5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "267f01ace3b2424ba27e83f13e85c1e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_099d48c315f940ba887142d0b9150c86",
            "max": 6101,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c580d7a634a54b4fae6f07eedf9bd3b2",
            "value": 6101
          }
        },
        "2758ffd089864c898db9d1f7a0e8d0fa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2914bb5a931f474690ce3138c6674cd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f72aa16946ab446ebe2358c864426999",
            "placeholder": "​",
            "style": "IPY_MODEL_69732fa3642643249be53cf913b54679",
            "value": " 1/1 [00:00&lt;00:00, 13.89 examples/s]"
          }
        },
        "2bc0011c15c34fcdb89cecfaf702787b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2daae658f29548b3aa7874905fa2085a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "307973e6c0cf48e4b33d123fc69be668": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33a6c33274c5461d80f9f77579c8b3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de4eea5277e34cefa537e014923fae5e",
            "placeholder": "​",
            "style": "IPY_MODEL_bc6e5bc1c3d149169debc876db942541",
            "value": " 1/1 [00:00&lt;00:00, 36.67 examples/s]"
          }
        },
        "34415fc12ddd40ec942d8af2bab3c054": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34dd472d33c244059cdd3396c45fffac": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "37a4d5482d67470d9c39b7b07019fcc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39cba0a6253c441c809dcc96226e24b8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d4871114571462f89d3e3a39d018c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3da9c708cce349c49232a817edf9e4e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab8d4c408dfb4c37a1735845284fe5c0",
              "IPY_MODEL_045ee62631f24abd903d94a7dc7de6ac",
              "IPY_MODEL_15212aad999f44a9ad0daab5fb585a17"
            ],
            "layout": "IPY_MODEL_9dfce5263b544e4db5d943b3f0d3b23a"
          }
        },
        "419dce4950e543d8b15855c67fa662cc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "433728dba5a5452fb8b1fe3a966e8f28": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4480e4c8e73248aabe7ed59471e0e69c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4612cf302057460c8b4837ca83102dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "463358cf7af54c83a13a640db5f073b6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4636cff815414408bb3a0903c38e0de5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48a8374f0835482cafaae4ee6838f79c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cc020ebb3672434ea09a98c9ddb82615",
              "IPY_MODEL_267f01ace3b2424ba27e83f13e85c1e3",
              "IPY_MODEL_e40a4e4a6bbb45e1805ecd736b629ec8"
            ],
            "layout": "IPY_MODEL_419dce4950e543d8b15855c67fa662cc"
          }
        },
        "4a4c97b4bf784afbb082e9dad2d0183d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f63a36c9d89848048de64916654054bf",
            "max": 1355256,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0366b145a95449328c6f657a7a2902aa",
            "value": 1355256
          }
        },
        "4bfffad11d8847f3a915b6d4f92057b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5215a54b3074ad7b13f956a07567730",
            "placeholder": "​",
            "style": "IPY_MODEL_151de66e80f340f9bf601b1e3e25a421",
            "value": "Generating test split: 100%"
          }
        },
        "4c2d16d50d094b55aa3bdd3db1d0f417": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a4b9b3a951a45a7a5c35f498d64bc6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b12b6e68dd243f6ae52b00912ddb543": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b655f2e4340407fa6ad78346f9c8639": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5efe2a70ac824d8ea35dcc62cdc8dd82": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89c31d946e344638a8b0099cdde67335",
            "placeholder": "​",
            "style": "IPY_MODEL_116888c72e474c798ad60c3955ca3711",
            "value": "vocab.json: 100%"
          }
        },
        "615c8bdc61ca4001af0f0216c9134a30": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69732fa3642643249be53cf913b54679": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6dc1d362becf4887a4edefdb355d88eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f80569c99334c79b6956f1dc7a6a004": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_beb358cafb5848238bc9e3e759134670",
            "placeholder": "​",
            "style": "IPY_MODEL_dc6d907bf21746eead05056201d9e17a",
            "value": " 1.04M/1.04M [00:00&lt;00:00, 19.8MB/s]"
          }
        },
        "71556afa13d149c080359e60da14ccd5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72947b90ee174f6ca3b921da9b2f2ed4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_159704455da24d5c921dad671b711f83",
            "max": 3731,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a19ac071607a4c729b6a43e50f9c501f",
            "value": 3731
          }
        },
        "731129cc7755460db8cff585812fbd16": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b655f2e4340407fa6ad78346f9c8639",
            "max": 1042301,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef405ef7ba73409b945b3479b2b42bc1",
            "value": 1042301
          }
        },
        "76c48825ee804b0daa33b146b6f29352": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "787f2f9a94624d51a31f83d3797eb30c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7a6e4d6aaef7414097c83eeb7f2eb94c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bc1df8c8b554905bc58b4be353fc3b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_463358cf7af54c83a13a640db5f073b6",
            "max": 1115394,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_37a4d5482d67470d9c39b7b07019fcc7",
            "value": 1115394
          }
        },
        "7d03504d64594fc08149d45f87273fae": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7f8cebe472494317aff3d88375d476df": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "82f6fe8978fd4a198bc74e9085e10005": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "86a5a2f4678149e38f7a8961be08f00b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87712890938c4e9abea53114a1b62084": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89c31d946e344638a8b0099cdde67335": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ad51c89023e45fba680edee580d40ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f8190896aee846119d15052e6483acfe",
              "IPY_MODEL_021fb054a4c34413ae675d923323cf81",
              "IPY_MODEL_0d6d28dbfbb145dba0d0419ba8bfe741"
            ],
            "layout": "IPY_MODEL_fe43beb413ad4d3abbe10def00a20f3a"
          }
        },
        "8b71050225d64465bc9e3a1f3e6b4fa0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71556afa13d149c080359e60da14ccd5",
            "placeholder": "​",
            "style": "IPY_MODEL_ab44205b591040008cfcd38b514bdf9e",
            "value": "tiny_shakespeare.py: 100%"
          }
        },
        "8f6e5436a3a14f25be8f342b9d8fef84": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95fc890fc1d14f12ab20fab62965845a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "969d7128c95b4d96b9a88b19047941f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6e6289210974699879732edd0aa4714",
              "IPY_MODEL_0ba80e0e0e6944758ece0e6dcb0338f3",
              "IPY_MODEL_007c89c59d8e48a48d19898f7698aedc"
            ],
            "layout": "IPY_MODEL_5b12b6e68dd243f6ae52b00912ddb543"
          }
        },
        "9988673546324902a76369dfda65aa47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d2a351135e42929a0515e0bd483c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4636cff815414408bb3a0903c38e0de5",
            "placeholder": "​",
            "style": "IPY_MODEL_c0b761c543894f83933693d0fe8affda",
            "value": " 1/1 [00:00&lt;00:00, 24.89 examples/s]"
          }
        },
        "9c0be4f8a2ab4516ac793727f5366a6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_20127fac11fc45b6a4aecadedbfbd5ee",
              "IPY_MODEL_7bc1df8c8b554905bc58b4be353fc3b8",
              "IPY_MODEL_deebdf3841c1450e831a6245d010bb89"
            ],
            "layout": "IPY_MODEL_bcc076863d9649ebb1261c267c00ebcf"
          }
        },
        "9dfce5263b544e4db5d943b3f0d3b23a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f4077d7ea9348d4b1b0feeeb96b3e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a19ac071607a4c729b6a43e50f9c501f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a31a96b22da3435b814190a61ff161dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9988673546324902a76369dfda65aa47",
            "placeholder": "​",
            "style": "IPY_MODEL_4612cf302057460c8b4837ca83102dcb",
            "value": "tokenizer.json: 100%"
          }
        },
        "a339a69c714b425494ea7fa9ed8ac86d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b71050225d64465bc9e3a1f3e6b4fa0",
              "IPY_MODEL_72947b90ee174f6ca3b921da9b2f2ed4",
              "IPY_MODEL_ee88035ac2944594b4c392eae66b948a"
            ],
            "layout": "IPY_MODEL_307973e6c0cf48e4b33d123fc69be668"
          }
        },
        "ab44205b591040008cfcd38b514bdf9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ab8d4c408dfb4c37a1735845284fe5c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d03504d64594fc08149d45f87273fae",
            "placeholder": "​",
            "style": "IPY_MODEL_76c48825ee804b0daa33b146b6f29352",
            "value": "config.json: 100%"
          }
        },
        "b01bed25877a49d2a60fb6c23b461506": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eefe5ce1cf534f2daa31d9cd04f21dd0",
              "IPY_MODEL_f973b13ba5d4499d851aeee200399e52",
              "IPY_MODEL_2914bb5a931f474690ce3138c6674cd2"
            ],
            "layout": "IPY_MODEL_b6cc5724c72a4749aef923ea610834f0"
          }
        },
        "b0b74c63af3a41968ba1e40c0791b3fc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6cc5724c72a4749aef923ea610834f0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "baeda91319074e27bf4f507d4a64b9ef": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb7a144c438b4e7c80821273bf71b0eb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc6e5bc1c3d149169debc876db942541": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bcc076863d9649ebb1261c267c00ebcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bda00152caac45c591c85ecb2a0e3264": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "beb358cafb5848238bc9e3e759134670": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c0b761c543894f83933693d0fe8affda": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1c7cea2bd594f3fac9bb50c1bedebfc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c29fa66a298d4f09a8bd48a1598d8aab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d02542b747034c5390d3c30eb9080d5d",
            "placeholder": "​",
            "style": "IPY_MODEL_c90da13efaea458191ee0db0c5b84da8",
            "value": "Generating validation split: 100%"
          }
        },
        "c580d7a634a54b4fae6f07eedf9bd3b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c90da13efaea458191ee0db0c5b84da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc020ebb3672434ea09a98c9ddb82615": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_615c8bdc61ca4001af0f0216c9134a30",
            "placeholder": "​",
            "style": "IPY_MODEL_e4485c11ae9a45d097fb6ab6614cd64f",
            "value": "README.md: 100%"
          }
        },
        "cf67dc7ff2bb40509c67d4eac0b3b34a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf8ada31bd3646adb993063a6045db6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d02542b747034c5390d3c30eb9080d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6e6289210974699879732edd0aa4714": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f6e5436a3a14f25be8f342b9d8fef84",
            "placeholder": "​",
            "style": "IPY_MODEL_787f2f9a94624d51a31f83d3797eb30c",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "d7c13642d1d64f46956a963304ae242f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc6d907bf21746eead05056201d9e17a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de4eea5277e34cefa537e014923fae5e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deebdf3841c1450e831a6245d010bb89": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb7a144c438b4e7c80821273bf71b0eb",
            "placeholder": "​",
            "style": "IPY_MODEL_2bc0011c15c34fcdb89cecfaf702787b",
            "value": " 1.12M/1.12M [00:00&lt;00:00, 13.6MB/s]"
          }
        },
        "e40a4e4a6bbb45e1805ecd736b629ec8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1c7cea2bd594f3fac9bb50c1bedebfc",
            "placeholder": "​",
            "style": "IPY_MODEL_7a6e4d6aaef7414097c83eeb7f2eb94c",
            "value": " 6.10k/6.10k [00:00&lt;00:00, 230kB/s]"
          }
        },
        "e4485c11ae9a45d097fb6ab6614cd64f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5215a54b3074ad7b13f956a07567730": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6544e6e9c5644fa983e887569e114e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c29fa66a298d4f09a8bd48a1598d8aab",
              "IPY_MODEL_1b999b8b0ae242d1a553f54140c19238",
              "IPY_MODEL_99d2a351135e42929a0515e0bd483c46"
            ],
            "layout": "IPY_MODEL_ea0c77ac9c68472faf576963bcaf9a64"
          }
        },
        "ea0c77ac9c68472faf576963bcaf9a64": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ee88035ac2944594b4c392eae66b948a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dc1d362becf4887a4edefdb355d88eb",
            "placeholder": "​",
            "style": "IPY_MODEL_07e2a08023cd4402a6f97c04ad108d56",
            "value": " 3.73k/3.73k [00:00&lt;00:00, 90.3kB/s]"
          }
        },
        "eefe5ce1cf534f2daa31d9cd04f21dd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf67dc7ff2bb40509c67d4eac0b3b34a",
            "placeholder": "​",
            "style": "IPY_MODEL_5a4b9b3a951a45a7a5c35f498d64bc6a",
            "value": "Generating train split: 100%"
          }
        },
        "ef405ef7ba73409b945b3479b2b42bc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "efaafc2a0969435eb74f55f260e1606a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f192cf1981c94506806eb9a19093b0c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86a5a2f4678149e38f7a8961be08f00b",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7f8cebe472494317aff3d88375d476df",
            "value": 1
          }
        },
        "f358b3cd52cb4db486b3dbe97c6346c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4bfffad11d8847f3a915b6d4f92057b3",
              "IPY_MODEL_f192cf1981c94506806eb9a19093b0c0",
              "IPY_MODEL_33a6c33274c5461d80f9f77579c8b3f4"
            ],
            "layout": "IPY_MODEL_10850bb4c5a84e469f9601bfc1e7dcb8"
          }
        },
        "f5545db5a29447f1aa2475df5fc58618": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7c13642d1d64f46956a963304ae242f",
            "placeholder": "​",
            "style": "IPY_MODEL_3d4871114571462f89d3e3a39d018c28",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 20.6MB/s]"
          }
        },
        "f63a36c9d89848048de64916654054bf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f72aa16946ab446ebe2358c864426999": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f74e9f85a49942a6b3a48e1748570153": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8190896aee846119d15052e6483acfe": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24a55b3942a744ecb79a758cf1c11cb5",
            "placeholder": "​",
            "style": "IPY_MODEL_f9484ff29a044589ab8ee217ae9b27c3",
            "value": "merges.txt: 100%"
          }
        },
        "f9484ff29a044589ab8ee217ae9b27c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f973b13ba5d4499d851aeee200399e52": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f74e9f85a49942a6b3a48e1748570153",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34dd472d33c244059cdd3396c45fffac",
            "value": 1
          }
        },
        "fe43beb413ad4d3abbe10def00a20f3a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
